<?xml version="1.0" encoding="utf-8"?>
<rss version="2.0" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:content="http://purl.org/rss/1.0/modules/content/">
    <channel>
        <title>datacraft blog Blog</title>
        <link>https://drkapichu.github.io/blog</link>
        <description>datacraft blog Blog</description>
        <lastBuildDate>Fri, 01 Apr 2022 00:00:00 GMT</lastBuildDate>
        <docs>https://validator.w3.org/feed/docs/rss2.html</docs>
        <generator>https://github.com/jpmonette/feed</generator>
        <item>
            <title><![CDATA[Fairness in AI - How a benchathon unlocked our knowledge]]></title>
            <link>https://drkapichu.github.io/blog/AI-Fairness-&amp;-benchathon</link>
            <guid>AI-Fairness-&amp;-benchathon</guid>
            <pubDate>Fri, 01 Apr 2022 00:00:00 GMT</pubDate>
            <description><![CDATA[ECRIRE UNE DESCRIPTION ICI]]></description>
            <content:encoded><![CDATA[<p><strong>TODO</strong>
<strong>- Changer author_url --&gt; mettre l&#x27;adresse mail d&#x27;Antoine I. ?</strong>
<strong>- Changer le titre dans le header.</strong>
<strong>- Mettre les tags les plus pertinents.</strong>
<strong>- Mettre les keywords les plus pertinents.</strong>
<strong>- Ã‰crire une description en env. 10 mots.</strong>
<strong>TODO</strong></p><hr/><h1>Fairness in AI - How a benchathon unlocked our knowledge</h1><p>Welcome to the second article of a series that aims at sharing how a group of private players (Danone, Ekimetrics, datacraft), researchers (Telecom Paris, Inria), and students (UniversitÃ© de Cergy), partnered to uncover fairness &amp; ethics in Artificial Intelligence from a practical standpoint. The group tried to tackle the following challenge: â€œhow should a Data Scientist concretely react when exposed to fairness concerns?â€. If you are interested to understand how this initiative kick started, have a look here <strong>TODO : Link to article</strong>.</p><p>This article casts a light on the benchathon - definition below - in which the group participated to get a quick and documented opinion of an already rich fairness/ethical ecosystem. It first explains how the concept of benchathon accelerated our practical grasp of the topic, and then explores the first conclusions drawn about the fairness ecosystem.</p><h2>Benchathon as an innovation catalyst</h2><p>At this stage of our â€œfairness journeyâ€, we had a decent high level understanding of what fairness could imply in real life. It was then the right time to start acting concrete: try and derive a pragmatic methodology, even if it implied implementing our own routines.</p><p>To that end, a very first step was to make sure weâ€™d not reinvent the wheel, and weâ€™d plainly benefit from existing open source contributions. This happened during a one-day benchathon. If you work in tech, you may already be familiar with the following two notions:</p><ul><li>Benchmark: <em>gathering and comparing qualitative information about how an activity is conducted through people, processes, and technology</em></li><li>Hackathon: <em>[short]<!-- --> event <!-- -->[...]<!-- --> in which computer programmers and others involved in software development <!-- -->[...]<!-- --> collaborate intensively on software projects</em></li></ul><p><strong>TODO: two footnotes here</strong></p><p>Hackathons usually involve teams that compete on the â€œsame topicâ€ for 2 to 3 days. Because we were limited in time - 1 day, rather than focusing all on the same â€œthingâ€, we decided to make the most out of the presence of 9 data scientists: we shared and split between us the technical analysis of several fairness open source libraries - <a href="https://github.com/Trusted-AI/AIF360">AIF360</a>, <a href="https://github.com/MAIF/shapash">Shapash</a>, <a href="https://github.com/dssg/aequitas">Aequitas</a>, <a href="https://research.google/teams/brain/pair/">What if tool</a> <strong>TODO: j&#x27;ai l&#x27;impression que ce lien n&#x27;est pas le bon</strong>, <a href="https://fairlearn.org/">Fairlearn</a>. Hence the concept of benchathon.</p><p>Even though all of us were entitled as â€œData Scientistsâ€, we all came from different structures, different backgrounds, and different (coding) habits. That diversity definitely triggered (and still does) great discussions and perspectives along the initiative. Still, an important step during the benchathon was to settle on an interpretation grid that would make the outcome as reusable and general as possible, and as unbiased as possible - in line with the topic then :). A few criteria were identified:</p><p><strong>TODO: table to insert here</strong></p><table><thead><tr><th><strong>Criteria</strong></th><th><strong>Description</strong></th><th><strong>Scale</strong></th></tr></thead><tbody><tr><td>Installation</td><td>How easy is it to get started?</td><td>1.5</td></tr><tr><td>Usability</td><td>How easy to use is the API?</td><td>1.5</td></tr><tr><td>Documentation</td><td>How well documented is the library?</td><td>1.5</td></tr><tr><td>Completeness</td><td>Does the library perform everything it is supposed to?</td><td>1.5</td></tr><tr><td>Reliability</td><td>Does the library seem reliable? (code quality, tests, â€¦)</td><td>1.5</td></tr><tr><td>Legitimacy</td><td>Is the library popular within the community? (number of stars on GitHub, latest commit, number of issues, â€¦)</td><td>1.5</td></tr><tr><td>Future</td><td>Gut instinct - would you trust it and use it in real projects?</td><td>Y/N</td></tr><tr><td>Weaknesses</td><td>What is currently missing?</td><td>N/A</td></tr></tbody></table><p>That being set, what was important was also to pace the day, so that despite the fact that small groups worked independently, we always kept an overall coherence and dynamics. It meant:</p><ul><li>Mini sprints of 1,5 hours</li><li>At the end of each mini sprint, a quick roundtable to share insights or blocking points, and get challenged by the whole group</li><li>Lunch break altogether: everyone brought something to share. This was a great moment of conviviality. It would even seem that a new datacraft initiative was born at this very moment, stay tuned!</li><li>At the end of the day, wrap up session during which each group made a demo of the library it spent the day on, and made sure to fill out above-mentioned criteria. The latter was especially important because this is what helps us today to have a concrete reference that every one can refer to.</li></ul><p>Taking a step back, below are a few takeaways:</p><ul><li>This benchathon was extremely productive: in the matter of only a day, our practical grasp of the fairness/ethical ecosystem clearly passed a milestone (see next section).</li><li>All people around the table had a developer background, and the same objective - namely, uncovering the fairness topic from a technical &amp; practical standpoint. It helped to get started fairly quickly, and proved that this format was a great fit for that audience and purpose.</li><li>One mistake we made was not to invest enough time beforehand in mapping the main open source libraries available in the AI community. It turns out we missed what would become our GO TO in the future: <a href="https://github.com/ModelOriented/DALEX">Dalex</a>.</li></ul><h2>Highlight of 6 ethical/fairness libraries</h2><p>If you are further interested in the exhaustive findings on the five libraries that were studied during the benchathon, please follow this <a href="https://docs.google.com/spreadsheets/d/1Z071Ih9S7XYEcXBoX4k7SNoy6Z5DqbUM6htcpn1J_WU/edit#gid=0">link</a>. The following section aims at providing a (subjective) summary of these libraries, in increasing relevance order, with respect to fairness / ethics.</p><h3>Shapash</h3><p><a href="https://github.com/MAIF/shapash">Open source library</a> developed by MAIF - a French insurance actor, and Quantmetry - a French AI consultancy, that mainly focuses on interpretability (no built-in fairness-oriented feature). It acts as a layer on top of the usual interpretability toolbox (feature importance, SHAP values, â€¦). It comes with a very decent web interface, high quality code, and a great community/documentation. It also provides an audit report of the project (from data prep to modeling, to exploratory analysis).</p><p>In a nutshell: great project, but not that relevant (yet?) for fairness topics.</p><p><strong>TODO: picture with legend to add</strong></p><h3>What if tool</h3><p><a href="https://pair-code.github.io/what-if-tool/">Open source interface</a> developed by Google. It mainly aims at conducting counterfactual analysis (â€œwhat would be the machine learning model prediction if we changed the value of that particular attribute, like the sex e.g.?â€). It comes with a decent web interface, especially to deal with unstructured data like images. Documentation is however not handy to deal with.</p><p>In a nutshell: great interface. However, counterfactual analysis is only one (important) feature among the different aspects related to fairness, which in turn does not justify a lock-in with that specific tool.</p><p><strong>TODO: picture with legend to add</strong></p><h3>Aequitas</h3><p><a href="http://aequitas.dssg.io/">Aequitas</a> is a bias and audit toolkit developed by Carnegie Mellon University. It aims at spotting unfair allocation compared to population repartition or wrong decisions about certain groups of people. It comes with a web interface (which we could not make work) and a Python library to help compute fairness metrics. Documentation is decent, especially their representation of the <a href="http://www.datasciencepublicpolicy.org/our-work/tools-guides/aequitas/">&quot;fairness tree&quot;</a>, which helps to navigate the (many and ambiguous) fairness metrics, depending on the use case.</p><p>In a nutshell: Aequitas is a tool that has been available for quite some time now, but that does not benefit from a living community. To be kept under the radar (or contribute to!).</p><p><strong>TODO: picture with legend to add</strong></p><h3>Fairlearn</h3><p><a href="https://fairlearn.org/">Fairlearn</a> is an open source library maintained by diverse contributors (from Microsoft, Zalando, â€¦). It aims at tackling each step of the fairness value chain. It implements fairness metrics, of which you have a summary below:</p><p><strong>TODO: picture with legend to add</strong></p><p>Fairlearn implements mitigation techniques:</p><ul><li>Pre-processing methods: alter a training set before training a model (example in fairlearn: removing sensitive correlations)</li><li>In-processing method: train a model (or a sequence of models) accounting for fairness constraints (example in fairlearn: exponentiated gradient <!-- -->[2]<!-- -->)</li><li>Post-processing methods: alter predictions to account for fairness constraints, once a model is trained (example in fairlearn: threshold optimization post processing algorithm <!-- -->[3]<!-- -->)</li></ul><p>It also tries to go beyond the usual binary classification problem, which is the usual go-to when uncovering the fairness topic (e.g. giving a try at regression). However, making our way through the â€œget startedâ€ procedure or the documentation - yet well designed and appealing, was no easy task. Note that the library also comes with nice dashboards that allow, among others, model comparison.</p><p>In a nutshell: promising and active library for fairness topics. Accessibility could be improved. To definitely keep an eye on (or contribute to!).</p><p><strong>TODO: picture with legend to add</strong></p><h3>AIF360</h3><p><a href="http://aif360.mybluemix.net/">AIF360</a> is an open source library developed by IBM. From our perspective, and before doing this initiative, this library was considered as the go-to for tackling fairness topics. It comes with an online tool, implements a wide range of mitigation techniques:</p><ul><li>Pre-processing methods among which reweighting <!-- -->[4]<!-- -->, or learning fair representations <!-- -->[5]</li><li>In-Processing methods: grid search reduction <!-- -->[6, 7]</li><li>Post-processing methods: equalized odds postprocessing <!-- -->[8, 9]</li></ul><p>It also benefits from a wide community, and comes with a user-friendly web interface. </p><p>However rich in terms of features / mitigation techniques, the documentation is quite poor (it is not unusual to go and directly look into the source code to get answers). Besides, (useful) snippets of code are disseminated in various Jupyter notebooks, which slows down the appropriation. Last, some choices regarding data representation (formatting) and/or object declaration/instantiation (like the main explainer object, which is quite verbose), led us to troubles when trying to get used to the library.</p><p>In a nutshell: AIF360 is a very rich and mature ecosystem. Accessibility is however currently an obstacle to its full exploitation.</p><p><strong>TODO: picture with legend to add</strong></p><h2>Conclusion</h2><p>At this point in time, we had discovered very interesting libraries, some of them backed by great communities and capabilities. Still, some open points remained that we thought would be worth investing time on:</p><ul><li>There was no clear winner: each library came with pros and cons. An ideal tool should be able to combine the best of each.</li><li>All those tools were very much focused (and still are) on the tooling, namely implementing a wide set of mitigation techniques or fairness dashboards. However, we were still missing a systematic framework for tackling fairness topics, that not only would make practical tools available, but that would also provide the associated reasoning: what question should a data scientist ask themselves? In which situation? Who should take part in this or that sensitive decision with respect to the model, â€¦?</li></ul><p>This is what will be tackled in the third article of this series. Weâ€™ll introduce Dalex, another library that will be used as a foundation to derive (our interpretation of) the whole reasoning when exposed to fairness / ethical concerns.</p>]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[A list of possible styles (stolen everywhere)]]></title>
            <link>https://drkapichu.github.io/blog/html</link>
            <guid>html</guid>
            <pubDate>Wed, 02 Mar 2022 00:00:00 GMT</pubDate>
            <description><![CDATA[Ceci est une aide-mÃ©moire pour liste les possibilitÃ©s de styles dans du MarkDown]]></description>
            <content:encoded><![CDATA[<p>Ceci est un lien vers un site qui liste les balises HTML avec des exemples (!!) : <a href="https://developer.mozilla.org/fr/docs/Web/HTML/Element/Img">https://developer.mozilla.org/fr/docs/Web/HTML/Element/Img</a></p><p>Essentially stupid thing you can find anywhere on the web because they&#x27;re basics. But you&#x27;re lazy man!!</p><h1>Ceci est une liste avec un titre</h1><h2>Etre un bÃ©nÃ©vole Data For Good</h2><p>Mais en pratique Ãªtre bÃ©nÃ©vole cela veut dire : </p><ul><li>Faire partie d&#x27;une communautÃ© tech engagÃ©e</li><li>Participer aux saisons d&#x27;accÃ©lÃ©ration</li><li>... Bref, Data For Good est une communautÃ© libre et indÃ©pendante, tu peux proposer ce que tu veux !</li></ul><p>Pour plus de dÃ©tails tu peux lire la page <a href="https://dataforgood.slite.com/p/channel/F9UR6bhuYCPAtvfLDje8Zc/notes/t1KTZaDgs">suivante</a>. </p><hr/><h2>Le Slack Data For Good</h2><p>Slack est un outil de messagerie communautaire, c&#x27;est aujourd&#x27;hui le coeur de la communautÃ© oÃ¹ se passe les discussions entre volontaires, l&#x27;organisation autour des projets, et oÃ¹ se partagent Ã©vÃ¨nements, offres d&#x27;emploi, liens et actualitÃ©s de l&#x27;association. Pour rejoindre le Slack, c&#x27;est simple il suffit de remplir le questionnaire ci-dessus. </p><p><img src="./img/2022-03-02-CSSStyle/slack.png" alt="slack"/></p><hr/><h1>Internal links</h1><p>Visitez la page <a href="/blog">ğŸ”¥ Blog</a> pour dÃ©couvrir nos accÃ©lÃ©rations depuis 2014.</p><hr/><h1>Un bouton cliquable qui redirigent vers un site extÃ©rieur</h1><div style="text-align:center;margin-bottom:20px"><a href="https://airtable.com/shrPjA75ckEgQdPUF" target="_blank" class="button button--secondary button--lg button-home"> Rejoindre la communautÃ© - 5min â±</a></div><iframe id="inlineFrameExample" title="Inline Frame Example" width="300" height="200" src="https://www.openstreetmap.org/export/embed.html?bbox=-0.004017949104309083%2C51.47612752641776%2C0.00030577182769775396%2C51.478569861898606&amp;layer=mapnik"></iframe><hr/><h1>Include an audio reader</h1><figure><figcaption>Listen to the T-Rex:</figcaption><audio controls="" src="roar.wav" type="audio/wav">Your browser does not support the <code>audio</code> element.</audio></figure><audio controls="" src="Kalimba.mp3">Your browser does not support the <code>audio</code> element.</audio><hr/><h1>Un lecteur intÃ©grÃ© de vidÃ©os (Youtube)</h1><iframe width="85%" height="500px" src="https://www.youtube.com/embed/0xtPrTo-13o" alt="PrÃ©sentation de datacraft par Isabelle" title="YouTube video player" frameBorder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe><hr/><h1>Faire des blocs tips, infos,</h1><p>:::tip On peut mettre un titre ici (pas obligatoire)</p><p><strong>La charte va au-delÃ  du cadre lÃ©gislatif</strong> afin de promouvoir lâ€™utilisation Ã©thique des donnÃ©es et de prÃ©venir de potentiels scandales liÃ©s aux donnÃ©es et Ã  lâ€™intelligence artificielle. Lâ€™objectif est de faire grandir la responsabilitÃ© individuelle et collective des data scientists en suscitant une rÃ©flexion et des Ã©changes sur lâ€™impact social de leur activitÃ© professionnelle.</p><p>:::</p><p>:::info</p><p><strong>La charte va au-delÃ  du cadre lÃ©gislatif</strong> afin de promouvoir lâ€™utilisation Ã©thique des donnÃ©es et de prÃ©venir de potentiels scandales liÃ©s aux donnÃ©es et Ã  lâ€™intelligence artificielle. Lâ€™objectif est de faire grandir la responsabilitÃ© individuelle et collective des data scientists en suscitant une rÃ©flexion et des Ã©changes sur lâ€™impact social de leur activitÃ© professionnelle.</p><p>:::</p><p>:::info Data For Good</p><p>La communautÃ© Data for Good compte plus de 2500 volontaires qui consacrent plusieurs heures par semaine au service de projets d&#x27;intÃ©rÃªt gÃ©nÃ©ral.</p><p>Vous Ãªtes Data Scientists/Analyst/Engineers, Developers, UX/UI designer, ou Project Manager ? <a href="https://airtable.com/shrPjA75ckEgQdPUF">Rejoignez-nous</a> !</p><p>:::</p><p>:::tip Rejoindre la communautÃ© Data For Good</p><p>Pour rejoindre la communautÃ©, il vous suffit de remplir ce <a href="https://airtable.com/shrPjA75ckEgQdPUF">questionnaire</a> !<br/>
Il vous sera donnÃ© un accÃ¨s au <a href="#le-slack-data-for-good">Slack</a> qui est le coeur de la communautÃ©.</p><p>:::</p><hr/><h1>Faire des capsules dÃ©pliantes</h1><details><summary><p>Principe #4 - Ne pas collecter ou utiliser de <strong>donnÃ©es inutilement personnelles et/ou sensibles</strong>.</p></summary><div><p><em>Etape projet (2): Je collecte ou je dispose de donnÃ©es</em></p><p>... et une Â« donnÃ©e sensible Â» ?</p><p>Lâ€™<a href="https://www.cnil.fr/fr/reglement-europeen-protection-donnees/chapitre2#Article9">article 9 du RÃ¨glement GÃ©nÃ©ral sur la Protection des DonnÃ©es (RGPD)</a> prÃ©voit que Â« le traitement des donnÃ©es Ã  caractÃ¨re personnel qui rÃ©vÃ¨le l&#x27;origine raciale ou ethnique, les opinions politiques, les convictions religieuses ou philosophiques ou l&#x27;appartenance syndicale, ainsi que le traitement des donnÃ©es gÃ©nÃ©tiques, des donnÃ©es biomÃ©triques aux fins d&#x27;identifier une personne physique de maniÃ¨re unique, des donnÃ©es concernant la santÃ© ou des donnÃ©es concernant la vie sexuelle ou l&#x27;orientation sexuelle d&#x27;une personne physique sont interdits Â».</p></div></details><p>Ici un peu de texte.</p><hr/><h1>Une image et du texte cÃ´te Ã  cÃ´te.... Ne marche pas !!</h1><section class="light-green"><div class="container main-section"><h1>L&#x27;association Data For Good</h1><div class="row"><div class="col col--6"><img src="./img/events.jpg" alt="dfg-demoday" style="width:100%;margin-bottom:20px"/></div><div class="col col--6" style="text-align:left;align-content:center"><p>Data For Good est une association loi 1901 (<i>100% bÃ©nÃ©vole, 100% open-source, 100% citoyenne</i>) crÃ©Ã©e en 2014 qui rassemble une communautÃ© de <b>2700+ volontaires</b> tech (Data Scientists, Data Analysts, Data Engineers, Developers, UX/UI Designers, Product &amp; Project Owners) souhaitant mettre leurs compÃ©tences au profit d&#x27;associations, d&#x27;ONG, et de l&#x27;ESS - et de s&#x27;engager pour l&#x27;intÃ©rÃªt gÃ©nÃ©ral.</p><p>Nous rÃ©alisons chaque annÃ©e des <b>saisons d&#x27;accÃ©lÃ©ration oÃ¹ une dizaine de projets sont accompagnÃ©s par les bÃ©nÃ©voles sur des thÃ©matiques sociales, sociÃ©tales et environnementales</b>. Nous avons ainsi accompagnÃ©, accÃ©lÃ©rÃ© et co-construits plus de 100 projets depuis 2014.</p><p>Nous sommes Ã©galement fervents <b>critiques des risques et des dÃ©rives de la technologie</b>, faire partie de la communautÃ© est aussi s&#x27;engager pour une technologie sobre et respectueuse des enjeux sociaux et environnementaux, et accepter que la technologie n&#x27;est pas la solution Ã  tous les problÃ¨mes.</p></div></div></div></section><hr/><h1>Different kinds of links</h1><ul><li>Airtable : <a href="https://airtable.com/privacy">https://airtable.com/privacy</a> </li><li>Mailchimp : <a href="https://mailchimp.com/legal/privacy/">https://mailchimp.com/legal/privacy/</a> </li><li>Slack : <a href="https://slack.com/trust/privacy/privacy-policy">https://slack.com/trust/privacy/privacy-policy</a></li></ul>]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[This is a test for the actions]]></title>
            <link>https://drkapichu.github.io/blog/testou</link>
            <guid>testou</guid>
            <pubDate>Mon, 28 Feb 2022 00:00:00 GMT</pubDate>
            <description><![CDATA[C'est un test pour faire fonctionner l'action GitHub]]></description>
            <content:encoded><![CDATA[<p>(setq markdown-css-paths &#x27;(&quot;./custom_blog.css&quot;))</p><p>My fucking test</p><p>This is a fucking new post with GitHub automatic Actions!</p><p>.</p><p>.</p><p>.</p><p><strong>Cet article est payant. TOutefois je l&#x27;ai sur mon ordi, dans les documents de l&#x27;Ã©gypto, mais il est particuliÃ¨rement long et structurÃ© d&#x27;une maniÃ¨re que je ne pourrais pas reproduire en markdown.</strong></p><p><strong>Que faire ?</strong>
.</p><p>.</p><p>.</p><hr/><h1>Un titre</h1><p><img src="./img/2022-02-28-GitHubActions/Gozilla6.jpg" alt="image" title="**Some text**"/></p><p>And here I write some text to have something to commit!!!</p><p>This is a new day, a new year, a new life.
Another brick in the wall..
Tada</p><link href="./custom_blog.css" rel="stylesheet"/><p class="my_style">Ceci est un test </p><p class="red">red fucking text</p><p>&lt;my_style&gt;this is a test&lt;/my_style&gt;</p><script src="https://gist.github.com/ollytheninja/8498790.js"></script><hr/><abbr> this is a test </abbr>]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[Comment veiller Ã  ce que les biais humains nâ€™imprÃ¨gnent pas les algorithmes ?]]></title>
            <link>https://drkapichu.github.io/blog/biais-humains-et-algorithmes</link>
            <guid>biais-humains-et-algorithmes</guid>
            <pubDate>Fri, 18 Feb 2022 00:00:00 GMT</pubDate>
            <description><![CDATA[Article publiÃ© dans Usbek & Rica le 18 fÃ©vrier 2022]]></description>
            <content:encoded><![CDATA[<hr/><div style="margin-top:1em;margin-bottom:2em"><div class="warning" style="font-size:28px;color:#69337A;padding:1.0em"> Stephanie Lehuger, Thinker et Entrepreneur, membre du <u>club datacraft</u>, qui rÃ©flÃ©chit aux questions Ã©thiques soulevÃ©es par lâ€™IA, nous explique dans cette tribune de quels outils et mÃ©thodes nous disposons actuellement pour quâ€™un prÃ©jugÃ© humain ne se retrouve pas dans lâ€™algorithme dâ€™une intelligence artificielle.</div></div><p>Tous les humains ont des biais cognitifs, câ€™est inÃ©vitable. Et les data scientists sont des humains, donc ils sont fatalement sujets aux biais, comme tout le monde. Pour Ã©tablir des connaissances, les data scientists analysent des donnÃ©es. Et ces donnÃ©es, si elles sont mal choisies, donnent de mauvais rÃ©sultats. Ainsi, un biais cognitif se transforme en biais de donnÃ©e qui se transforme ensuite en biais algorithmique.</p><p>On peut dire quâ€™un algorithme fonctionne comme une recette de cuisine oÃ¹ les ingrÃ©dients seraient les donnÃ©es et la recette le code : si les ingrÃ©dients (les donnÃ©es) sont de mauvaise qualitÃ©, avec des biais par exemple, le rÃ©sultat ne peut quâ€™Ãªtre dÃ©cevant. La plupart du temps, les biais proviennent des donnÃ©es et cela se produit de deux maniÃ¨res.</p><p>En premier lieu, ils peuvent Ãªtre le rÃ©sultat dâ€™une mauvaise collecte. Imaginons par exemple quâ€™on cherche Ã  dÃ©terminer le loyer moyen que paient les gens qui louent leur logement. Si les data scientists sont parisiens et rÃ©cupÃ¨rent la base de donnÃ©es de leur ville, ils vont obtenir un rÃ©sultat Ã©levÃ© par rapport Ã  la moyenne nationale. Il sera biaisÃ© par les loyers de Paris.</p><p>La transmission dâ€™un biais sâ€™effectue donc au travers des donnÃ©es choisies (la Â« data Â»). Si les data scientists nâ€™ont pas conscience que les loyers sont moins Ã©levÃ©s dans les villes de taille moyenne et en zone rurale que dans les grandes villes et quâ€™ils entraÃ®nent un algorithme Ã  prÃ©dire le prix du loyer sur ces donnÃ©es-lÃ , alors ses prÃ©dictions seront biaisÃ©es aussi. Le biais dâ€™une IA peut provenir Ã  lâ€™origine dâ€™un biais cognitif humain, qui se transmet dans les donnÃ©es choisies qui sont biaisÃ©es, puis elles influencent ensuite les rÃ©sultats en sâ€™Ã©tant transformÃ©es en un biais algorithmique.</p><div style="margin-top:1em;margin-bottom:2em"><div class="warning" style="font-size:24px;color:#69337A;border-left:solid #805AD5 4px;padding:0.7em"> Sâ€™il existe une discrimination des femmes dans une entreprise, se baser sur les donnÃ©es passÃ©es pour Ã©valuer le potentiel dâ€™une candidate, mÃªme plus brillante quâ€™un concurrent masculin, lui sera dÃ©favorable</div></div><p>En deuxiÃ¨me lieu, les biais peuvent Ã©maner dâ€™une situation dÃ©jÃ  biaisÃ©e et quâ€™un algorithme pourrait amplifier. Comme une intelligence artificielle qui baserait son apprentissage sur des donnÃ©es historiquement biaisÃ©es. Si, depuis toujours, il existe une discrimination des femmes dans une entreprise, se baser sur les donnÃ©es passÃ©es pour Ã©valuer le potentiel dâ€™une candidate, mÃªme plus brillante quâ€™un concurrent masculin, lui sera dÃ©favorable. Si, historiquement, les femmes sont peu reprÃ©sentÃ©es, lâ€™algorithme pourra en dÃ©duire de maniÃ¨re erronÃ©e quâ€™elles ont un profil moins dÃ©sirable.</p><h2> Quelques exemples de biais communs </h2><p>Un biais typique quâ€™il faut tenter dâ€™Ã©viter est le biais des survivants. Par exemple, quand on constate que des bÃ¢timents de plus de cent ans sont encore debout, on a lâ€™impression que la Â« construction dâ€™antan Â» Ã©tait de meilleure qualitÃ© quâ€™aujourdâ€™hui. Pourtant, quand on y rÃ©flÃ©chit, la quasi-totalitÃ© de ce qui a Ã©tÃ© construit depuis lâ€™invention de la construction sâ€™est en fait Ã©croulÃ©e ou a Ã©tÃ© dÃ©molie, donc ces bÃ¢timents Â« survivants Â» sont des exceptions.</p><div style="margin-top:1em;margin-bottom:2em"><div class="warning" style="font-size:24px;color:#69337A;border-left:solid #805AD5 4px;padding:0.7em"> Les data scientists doivent Ã©viter le biais du survivant qui consisterait Ã  tirer des conclusions sur la base dâ€™une population incomplÃ¨te</div></div><p>Lors de lâ€™Ã©tude de donnÃ©es par des data scientists, il leur faut Ã©viter le biais du survivant qui consisterait Ã  tirer des conclusions sur la base dâ€™une population incomplÃ¨te, comportant uniquement les Ã©lÃ©ments ayant Â« survÃ©cu Â», qui sont en fait des exceptions, plutÃ´t que des cas reprÃ©sentatifs.</p><p>En France, des Â« antivax Â» ont Ã©tÃ© victimes du paradoxe de Simpson. Ils ont assurÃ© Ã  tort sur les rÃ©seaux sociaux que les non-vaccinÃ©s ne saturent pas les services de rÃ©animation du pays, en sâ€™appuyant sur des donnÃ©es de la Drees mal interprÃ©tÃ©es. Leur erreur principale est dâ€™avoir regardÃ© les chiffres bruts au lieu des pourcentages. Il y a en effet neuf fois plus de vaccinÃ©s que de non-vaccinÃ©s en France. </p><p>Alors que les non-vaccinÃ©s sont trÃ¨s minoritaires, ils sont surreprÃ©sentÃ©s Ã  lâ€™hÃ´pital, avec 63 % des admissions en soins critiques. Si on regarde les chiffres absolus, on peut avoir lâ€™impression que les deux populations sont en nombre Ã©quilibrÃ©s dans les hÃ´pitaux, mais ce serait oublier de regarder la proportion de chacune dans la population gÃ©nÃ©rale. Câ€™est ainsi que plusieurs enquÃªtes rÃ©centes menÃ©es sur des Ã©chantillons dâ€™hÃ´pitaux ont conclu que les non-vaccinÃ©s reprÃ©sentaient entre 70 % et 90 % dans les services de rÃ©animation.</p><h2> Comment les data scientists corrigent les biais ? </h2><p>Une fois quâ€™on a identifiÃ© pourquoi et comment les biais posent un problÃ¨me aux data scientists, on va sâ€™intÃ©resser Ã  ce que les data scientists font, ne font pas, et devraient faire pour limiter les risques liÃ©s Ã  ces biais.</p><h3> 1. Prendre conscience du problÃ¨me et se poser les bonnes questions </h3><p>Pour prendre conscience du problÃ¨me des biais cognitifs, les data scientists ont accÃ¨s Ã  diffÃ©rents types de ressources. Ils peuvent par exemple commencer Ã  sâ€™informer par le biais dâ€™une charte, comme la charte Ã©thique Ã©laborÃ©e au sein de datacraft. Ils peuvent par ailleurs analyser le contenu des rÃ©fÃ©rentiels dâ€™Ã©valuation de lâ€™IA de confiance, comme celui de Labelia Labs (ex-Substra Foundation) ou celui du LNE. Les serments Ã©tablissent Ã©galement une liste pertinente de critÃ¨res dâ€™une IA responsable, comme le font Tech pledge et Holberton-Turing Oath. Enfin, il existe des outils pratiques comme la checklist de Data Science Ã©thique deon, accessible en ligne de commande.</p><p>Il est important dâ€™avoir un esprit critique sur son propre travail quand on est data scientist. Si on ne devait choisir que 3 questions Ã  se poser absolument, voici ce que je propose :</p><ul><li>Sâ€™engager Ã  faire une pause pour sâ€™interroger sur toutes les consÃ©quences de son travail, quâ€™elles soient voulues ou non;</li><li>ContrÃ´ler les consÃ©quences de son travail dans le temps;</li><li>Tendre vers lâ€™autorÃ©gulation Ã  lâ€™aide de rÃ©fÃ©rentiel dâ€™Ã©valuation, de certification avec audit), en complÃ©ment des Â« 7 points de vigilance Â» soulignÃ©s par la Commission europÃ©enne.</li></ul><h3> 2. Mesurer les biais </h3><p>AprÃ¨s avoir pris conscience de la potentielle existence de biais, la seconde Ã©tape consiste Ã  dÃ©finir des mÃ©triques appropriÃ©es afin de les mesurer convenablement. Le choix des mÃ©triques dÃ©pend alors essentiellement de ce que lâ€™on cherche Ã  contrÃ´ler. Aequitas est une boÃ®te Ã  outils open source pour auditer les biais, crÃ©Ã©e par le Center for Data Science and Public Policy de lâ€™UniversitÃ© de Chicago. </p><p>Elle permet de vÃ©rifier les prÃ©dictions des outils dâ€™Ã©valuation des risques basÃ©s sur lâ€™apprentissage automatique afin de comprendre les diffÃ©rents types de biais et de prendre des dÃ©cisions Ã©clairÃ©es sur le dÃ©veloppement et le dÃ©ploiement de ces systÃ¨mes. Le Â« fairness tree Â» aide Ã  choisir la bonne mÃ©trique. LÃ  comme ailleurs, il convient dâ€™Ãªtre attentif aux choix rÃ©alisÃ©s puisquâ€™il existe un nouveau biais possible. En effet, il faut avoir conscience que, en choisissant une mÃ©trique, on Ã©carte toutes les autres.</p><div style="margin-top:1em;margin-bottom:2em"><div class="warning" style="font-size:24px;color:#69337A;border-left:solid #805AD5 4px;padding:0.7em"> Tout choix concernant une population Ã©tudiÃ©e devient moral en data science</div></div><p>Des mÃ©triques faciles dâ€™accÃ¨s pour les data scientists sont Ã©galement mises en Å“uvre. Une Ã©quipe au sein de datacraft a rÃ©alisÃ© une cartographie de 5 Â« fairness open source libraries Â» lors dâ€™un benchathon : AIF360, Shapash, Aequitas, What if tool, Fairlearn.</p><p>Tout choix concernant une population Ã©tudiÃ©e devient moral en data science. En dehors des trÃ¨s grands groupes qui ont conscience des risques rÃ©putationnels forts auxquels ils sont soumis sâ€™ils ne font pas attention aux biais et Ã  leurs consÃ©quences, cela reste principalement une question qui tient du ressort individuel dans les autres entreprises.</p><p>MÃªme si ce nâ€™est pas obligatoire lÃ©galement, il revient donc aux data scientists dâ€™Ãªtre moralement critiques sur leurs choix de donnÃ©es. Tout comme il est nÃ©cessaire dâ€™Ãªtre prudent pour ne pas introduire de biais dans les algorithmes quâ€™ils dÃ©veloppent.</p><h3> 3. Limiter les risques de biais </h3><p>Il existe de nombreuses mÃ©thodes pour rÃ©duire les biais, que lâ€™on peut diviser en trois grandes familles selon que lâ€™intervention du praticien se situe avant, pendant ou aprÃ¨s lâ€™entraÃ®nement de lâ€™algorithme. Avant lâ€™entraÃ®nement, ces mÃ©thodes consistent Ã  transformer les donnÃ©es Ã  disposition, par exemple en les repondÃ©rant.</p><p>ConcrÃ¨tement, on peut revoir la pondÃ©ration du nombre de personnes dans un jeu de donnÃ©es pour sâ€™assurer quâ€™il y a autant dâ€™hommes que de femmes et ainsi Ã©viter un biais de genre. Pendant lâ€™entraÃ®nement, il sâ€™agit dâ€™incorporer des contraintes dâ€™Ã©quitÃ© Ã  satisfaire, en complÃ©ment des objectifs de performance classique. Enfin, les mÃ©thodes dites de post-traitement consistent Ã  modifier les dÃ©cisions des algorithmes, par exemple en favorisant les sous-groupes discriminÃ©s.</p><div style="margin-top:1em;margin-bottom:2em"><div class="warning" style="font-size:24px;color:#69337A;border-left:solid #805AD5 4px;padding:0.7em"> Pour quâ€™une entreprise soit Ã  la fois juste et profitable, toutes les parties prenantes doivent Ã©changer pour parvenir Ã  des compromis acceptables</div></div><p>En diminuant les biais dâ€™un cÃ´tÃ©, on diminue gÃ©nÃ©ralement la performance des algorithmes de lâ€™autre : on parle du fairness-accuracy tradeoff. Pour quâ€™une entreprise soit Ã  la fois juste et profitable, toutes les parties prenantes doivent Ã©changer pour parvenir Ã  des compromis acceptables. Les data scientists, les dÃ©cideurs business ou encore les Ã©quipes de gouvernance sont impliquÃ©s dans ce processus complexe afin dâ€™aboutir Ã  un arbitrage. Une fois la dÃ©cision prise, lâ€™algorithme dÃ©ployÃ© et mis en production, il est indispensable de mettre en place une politique de supervision en temps rÃ©el (monitoring) afin de dÃ©tecter de possibles changements de comportement du modÃ¨le.</p><p>Pour rÃ©sumer, afin dâ€™Ã©viter de transmettre des biais humains Ã  une intelligence artificielle, les data scientists doivent faire preuve dâ€™esprit critique vis-Ã -vis de leurs possibles prÃ©jugÃ©s inconscients quand ils sÃ©lectionnent leurs donnÃ©es et construisent leurs algorithmes. Il nâ€™y a malheureusement pas de mÃ©thode miracle qui marche Ã  tous les coups. Un modÃ¨le repose sur des hypothÃ¨ses dÃ©pendantes dâ€™un contexte, elles seront donc diffÃ©rentes pour chaque problÃ¨me, sans quâ€™un modÃ¨le magique fonctionne pour tous.</p>]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[Few Shot Learning - application de la mÃ©thode iPET]]></title>
            <link>https://drkapichu.github.io/blog/draft</link>
            <guid>draft</guid>
            <pubDate>Fri, 04 Feb 2022 00:00:00 GMT</pubDate>
            <description><![CDATA[Draft of the first blog]]></description>
            <content:encoded><![CDATA[<p>(<a href="https://numenta.com/blog/2019/08/30/case-for-sparsity-in-neural-networks-part-1-pruning">source</a> de l&#x27;image de prÃ©sentaion)</p><hr/><h2>Quâ€™est ce que le Few Shot Learning (FSL) ? - titre alternatif : Sujet du jour : le Few Shot Learning (FSL)</h2><p>Il est bien connu que la puissance des mÃ©thodes de Machine Learning supervisÃ©es, et plus particuliÃ¨rement de Deep Learning avec les rÃ©seaux de neurones, depuis le dÃ©but des annÃ©es 2000, a reposÃ© sur la constitution de <strong>grands jeux de donnÃ©es labellisÃ©s</strong>. Deux Ã©lÃ©ments sont importants ici : â€˜grandsâ€™ et â€˜labellisÃ©sâ€™.</p><p>Pour le premier point, Ã§a reprÃ©sente par exemple des milliers, voire des millions dâ€™images pour la Computer Vision et des millions dâ€™ensembles de phrases pour le NLP. Concernant le second point, il signifie quâ€™au cours de son apprentissage, lâ€™ordinateur compare son Ã©valuation des donnÃ©es avec le label quâ€™un intervenant humain a associÃ© Ã  chaque donnÃ©e.</p><p>Dans le cas du <strong>Few Shot Learning (FSL)</strong>, les chercheurs veulent crÃ©er des mÃ©thodes capables dâ€™apprendre avec peu de donnÃ©es, i.e. des dizaines ou des centaines, ce qui reprÃ©sente un gain de temps et dâ€™Ã©nergie, tout en conservant des performances Ã©quivalentes aux modÃ¨les traditionnels bien sÃ»r. Câ€™est pourquoi en franÃ§ais on parle dâ€™<strong>apprentissage frugal</strong>. Toutefois, en pratique les mÃ©thodes de FSL prennent un modÃ¨le traditionnel, prÃ©-entraÃ®nÃ© sur un grand nombre de donnÃ©es, et elles le spÃ©cialisent sur le cas dâ€™usage via une courte phase dâ€™apprentissage sur le petit jeu de donnÃ©es Ã  disposition ; câ€™est du fine-tuning. Mais en plus, le Few Shot câ€™est une mÃ©thode qui va au-delÃ  des mÃ©thodes traditionnelles, elle permet de faire du semi-supervisÃ©, câ€™est ce quâ€™on va voir avec le cas dâ€™usage.</p><h2>Le cas dâ€™usage - titre alternatif : Câ€™est quoi le problÃ¨me ?!</h2><p>Ekimetrics sâ€™est intÃ©ressÃ© Ã  lâ€™apprentissage frugal pour exploiter les Ã©normes jeux de donnÃ©es des petits commentaires quotidiens sur internet, avec une problÃ©matique de gain de tempsâ€¦ De la frugalitÃ© avec des Ã©normes jeux de donnÃ©es ? On vous explique !</p><p>Mieux que le seul nombre dâ€™Ã©toiles dâ€™un restaurant ou dâ€™un hÃ´tel, il sâ€™agit de prendre en compte les avis dans les tweets, les posts, les brÃ¨vesâ€¦ qui sont par essence des donnÃ©es non labellisÃ©es et de les exploiter. Lâ€™annotation humaine de ces avis est inenvisageable. Ã‡a coÃ»terait trop cher, Ã§a prendrait trop de temps, et il faudrait recommencer tous les jours pour suivre lâ€™Ã©volution du sentiment. En l&#x27;occurrence, pour la recherche dâ€™Ekimetrics, le sujet dâ€™Ã©tude porte sur des commentaires de restaurants.</p><p>Mais si la machine Ã©tait capable dâ€™Ã©valuer les commentaires, Ã  2 Gigahertz, tout de suite le problÃ¨me serait rÃ©glÃ©. Câ€™est lÃ  que le Few Shot, en utilisant la mÃ©thode PET, peut devenir utile.</p><p>Dans la suite, nous vous prÃ©sentons la mÃ©thode PET, comment lâ€™utiliser dans le cadre du FSL et enfin, comment Ekimetrics lâ€™utilise sur les avis des consommateurs.</p><h2>PET quâ€™est ce que câ€™est ?</h2><p><strong>PET</strong> est lâ€™acronyme de â€˜<strong>Pattern Exploiting Training</strong>â€™. La mÃ©thode repose sur un ensemble fixe et prÃ©dÃ©fini de <strong>patterns</strong> et de <strong>verbalizers</strong> et un <strong>Pre-trained Language Model</strong> a.k.a. <strong>PLM</strong>. Les patterns sont les phrases Ã  trou (â€œIt wasâ€¦â€, â€œJustâ€¦!â€, â€œAll in all, it wasâ€¦â€, â€œIn summary, the restaurant isâ€¦â€) et les verbalizers sont les mots qui peuvent complÃ©ter ces phrases et auxquels sont associÃ©es des notes chiffrÃ©es. On commence Ã  retrouver les nombres que lâ€™ordinateur aime tant !</p><p>ConcrÃ¨tement, reprenons notre exemple des Ã©valuations des restaurants, la mÃ©thode consiste Ã  :</p><ul><li>prendre un commentaire,</li><li>y associer alÃ©atoirement un pattern,</li><li>soumettre le tout au PLM qui va le complÃ©ter en choisissant un verbalizer.</li></ul><p><img src="./img/2022-02-04-MindshakeTime/PET.png" alt="image" title="Schema of a basic PET"/>{:.image-left}</p><p>Par exemple (voir Fig. 1), avec le commentaire â€œBest pizza ever!â€, on construit la phrase Ã  trou : â€œBest pizza ever! It was â€¦ .â€ que le PLM va complÃ©ter avec â€˜greatâ€™ avec une confiance de 0.8, sachant que ce mot est notÃ© +1.</p><h2>FSL + PET : premiÃ¨re application aux avis internet</h2><p>Revenons Ã  la masse brute des avis des consommateurs sur internet. <strong>PET est la mÃ©thode</strong> pour associer une note Ã  un commentaire, le <strong>FSL est le moyen</strong> de traiter automatiquement tout le jeu de donnÃ©es, et le travail de lâ€™algorithme se fait en deux Ã©tapes.</p><p>Dans un premier temps, on labellise un petit nombre de commentaires, une centaine par exemple, ce qui signifie quâ€™on associe une paire pattern plus verbalizer Ã  ces commentaires, et on finetune le PLM avec cette centaine. Puis, une fois le PLM spÃ©cialisÃ©, on le laisse labelliser tout le reste du jeu de donnÃ©es, automatiquement. Ã‡a en fait une mÃ©thode semi-supervisÃ©e dâ€™analyse de sentiment des commentaires.</p><p>Cependant, cette application basique prÃ©sente des limites. Dâ€™une part, le verbalizer donnÃ© par le PLM peut ne pas Ãªtre le plus adaptÃ© au commentaire et, dâ€™autre part, câ€™est trÃ¨s ambitieux de spÃ©cialiser le PLM une fois sur une centaine dâ€™exemples pour ensuite en traiter des dizaines de milliers ou plus. Câ€™est pourquoi les chercheurs ont dÃ©veloppÃ© une mÃ©thode de distillation qui augmente la robustesse de PET, câ€™est la mÃ©thode <strong>iPET : iterative PET</strong>.</p><h2>i(terative)PET : une mÃ©thode de distillation astucieuse</h2><p>Une image peut valoir mille motsâ€¦</p><p><img src="./img/2022-02-04-MindshakeTime/iPET.png"/></p><p>â€¦ Mais quelques mots seront quand mÃªme nÃ©cessaires pour expliquer cette image !</p><p>Tout dâ€™abord, le schÃ©ma de gauche sur la figure prÃ©sente lâ€™adaptation de PET qui permet dâ€™obtenir le label le plus adaptÃ© au commentaireâ€¦ en moyenne. En effet, il sâ€™agit â€˜simplementâ€™ de <strong>faire travailler des mÃ©thodes PET indÃ©pendantes en parallÃ¨le</strong> (trois sur le schÃ©ma). Les trois cellules ont le mÃªme PLM au dÃ©part, et elles travaillent sur les mÃªmes commentaires, mais avec des patterns diffÃ©rents. Dans la phase dâ€™entraÃ®nement sur les donnÃ©es labellisÃ©es, les PLMs se spÃ©cialisent diffÃ©remment. Puis, durant la phase de travail, pour un mÃªme commentaire ils produisent des <strong>paires pattern-verbalizers</strong> (appelÃ©es <strong>PVPs</strong> sur le schÃ©ma) indÃ©pendamment les uns des autres ; possiblement les mÃªmes, mais pas avec les mÃªmes probas. Enfin, <strong>en sortie</strong> ces (trois) labels sont utilisÃ©s pour calculer <strong>un soft-label</strong>, i.e. un <strong>label moyen</strong>.</p><p>Ensuite, sur la droite est prÃ©sentÃ© le caractÃ¨re itÃ©ratif de la mÃ©thode iPET. Elle consiste Ã  diviser le jeu labellisÃ©s sur plusieurs itÃ©rations (indiquÃ©es par les exposants allant de 0 Ã  k) et Ã  diviser encore Ã  chaque itÃ©ration entre plusieurs mÃ©thodes parallÃ¨les (indiquÃ©es par les indices allant de 0 Ã  4). Mais attention, chacun des quatre modÃ¨les ici fait du soft-labelling comme prÃ©sentÃ© Ã  gauche de la figure, câ€™est-Ã -dire quâ€™ils contiennent plusieurs mÃ©thodes en parallÃ¨le.</p><p>Donc, si lâ€™on suppose que lâ€™on part pour trois itÃ©rations, lâ€™information labellisÃ©e est distillÃ©e de la maniÃ¨re suivante. Ã€ lâ€™itÃ©ration 0 sur le schÃ©ma, on prend un tiers des donnÃ©es labellisÃ©es, et on fournit un quart de ces donnÃ©es Ã  chaque modÃ¨le pour le finetuner, avant de prendre un tiers des donnÃ©es Ã  labelliser et dâ€™en fournir un quart Ã  chaque modÃ¨le pour soft-labellisation. Ce qui constitue la fin de la premiÃ¨re itÃ©ration.</p><p>Ã€ la deuxiÃ¨me itÃ©ration - itÃ©ration 1 sur le schÃ©ma, on commence Ã  nouveau par un phase de fine-tuning, mais avec un jeu de donnÃ©es labellisÃ©es constituÃ© pour partie des donnÃ©es annotÃ©es par un Ãªtre humain (le deuxiÃ¨me tiers), et pour partie de donnÃ©es soft-labellisÃ©es. Toutefois, on fait attention Ã  ce quâ€™un modÃ¨le ne sâ€™entraÃ®ne pas avec des donnÃ©es quâ€™il a lui-mÃªme soft-labellisÃ©, pour Ã©viter quâ€™il renforce ses biaisâ€¦ on distille ! Par exemple sur le schÃ©ma, Ã  lâ€™itÃ©ration 1, le jeu dâ€™entraÃ®nement T fourni au modÃ¨le 4, i.e. T14, est constituÃ© de donnÃ©es soft-labellisÃ©es par les modÃ¨les 1 et 2, en plus des donnÃ©es annotÃ©es par lâ€™humain. Puis on prend le deuxiÃ¨me tiers de donnÃ©es Ã  annoter, on en fournit un quart Ã  chaque modÃ¨le pour soft-labellisation et on finit la deuxiÃ¨me itÃ©ration.</p><p>Pour la troisiÃ¨me itÃ©ration, vous avez compris le principe je penseâ€¦   </p><p>Ã€ la fin, les millions de commentaires sont plutÃ´t bien soft-labellisÃ©s, Ã  la vitesse de la machine et au coÃ»t de lâ€™Ã©lectricitÃ©, tout est prÃªt pour un classifieur sur le schÃ©ma dâ€™Ekimetrics et je vous ai expliquÃ© tous les termes entourÃ©s sur la figure et prÃ©sentÃ© toutes les Ã©tapes. </p><h2>Avantages, inconvÃ©nients, limites et amÃ©liorations.</h2><p>Nous avons dÃ©jÃ  vu certains des avantages. Internet est une place sur laquelle il y a plÃ©thore dâ€™avis en tout genre : films, restaurants, hÃ´tels, produits de grande consommation, lieux diversâ€¦ Annoter ces donnÃ©es serait un travail coÃ»teux et sans fin, nous lâ€™avons dit. Lâ€™approche iPET permet dâ€™automatiser cette Ã©tape, Ã  la vitesse de lâ€™ordinateur et quel que soit le cas dâ€™Ã©tude.</p><p>Du point de vue des performances, Ekimetrics a indiquÃ© avoir une prÃ©cision de 88% avec seulement 50 donnÃ©es labellisÃ©es au dÃ©part, et mÃªme 84% avec 10 donnÃ©es labellisÃ©es !! En comparaison, les modÃ¨les supervisÃ©s peuvent atteindre des prÃ©cisions de 99%, mais au prix dâ€™un Ã©norme travail de prÃ©-traitement. Câ€™est donc un pas conceptuel de plus dans la rÃ©duction de la supervision.</p><p>Toutefois, le domaine dâ€™application se restreint Ã  des donnÃ©es textuelles assez courtes dâ€™une part. Et dâ€™autre part, la charge de travail est dÃ©placÃ©e vers une bonne conceptualisation du cas dâ€™Ã©tude. Les rÃ©sultats sont extrÃªmement dÃ©pendants de la formulation des patterns et des choix de verbalizers (i.e. choix du prompting). Ceux-ci impliquent une grande variabilitÃ© qui nâ€™est pas maÃ®trisÃ©e. De plus le PLM utilisÃ© - un modÃ¨le BERT dans le cas dâ€™Ekimetrics, cache des inconnues sur le corpus qui a servi Ã  son entraÃ®nement, son domaine dâ€™applicabilitÃ©, ses paramÃ¨tres. On touche lÃ  Ã  une limite dans laquelle lâ€™IA nâ€™est plus tout Ã  fait de lâ€™open science.</p><hr/><h1>Notes de Xavier que je n&#x27;ai pas mises</h1><h2>LIMITES et PISTES D&#x27;AMÃ‰LIORATIONS</h2><p>PLM ou Foundation modÃ¨le avec quelles donnÃ©es a-t-il Ã©tÃ© entraÃ®nÃ© ???</p><p>Que donnerait lâ€™utilisation de plusieurs PLM ?</p><p>une amÃ©lioration de ces approches est proposÃ© dans le papier <a href="https://arxiv.org/pdf/2103.11955.pdf">https://arxiv.org/pdf/2103.11955.pdf</a>.</p>]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[My first GitHub blog! (strongly inspired by Ekimetrics'...)]]></title>
            <link>https://drkapichu.github.io/blog/welcome</link>
            <guid>welcome</guid>
            <pubDate>Fri, 15 Oct 2021 00:00:00 GMT</pubDate>
            <description><![CDATA[Welcome to the first post! Short text, but sexy... People are eager to know more.]]></description>
            <content:encoded><![CDATA[<h1>And here is the content of my first blog...</h1><h2>Welcome to our technology website!</h2><p>We have been working in the Data Science industry for 15 years and are now the biggest pure player in Europe with 250+ data profiles. We have been benefiting from the open source community for a while, and we want to give back to the community by sharing insights on what we&#x27;ve learned over the years:</p><ul><li><a href="/blog">Blog</a> - read articles on various Data topics: from industrialization on cloud platforms to exotic Deep Learning algorithms</li><li><a href="/opensource">Open source contributions</a> - browse our own open source contributions (Python libraries, code snippets)</li></ul><p>ğŸ’Œ After reading behind the scenes of the Data Science Company, feel free to <a href="mailto:inno@ekimetrics.com">send us a email</a> for any questions or feedbacks! </p><h2>About Ekimetrics</h2><p>Ekimetrics is the first pure player in Data Science in Europe. We operate from Paris, London, New York and Hong Kong with 250+ Data Scientists, Data Engineers, Full Stack Developers, strategy consultants and UX designers. </p><p>We help companies steer their data opportunity, build data capabilities, and deploy actionable solutions, to power up marketing and operational performance, as well as (re)energizing business models. Our primary focus is to deliver immediate business gains, while guaranteeing sustainable data capital for our clients.</p>]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[Lâ€™artisanat de la science des donnÃ©es avec datacraft]]></title>
            <link>https://drkapichu.github.io/blog/datacraft-binaire</link>
            <guid>datacraft-binaire</guid>
            <pubDate>Tue, 23 Mar 2021 00:00:00 GMT</pubDate>
            <description><![CDATA[Article publiÃ© dans binaire le 23/03/2021]]></description>
            <content:encoded><![CDATA[<p>Cet article a Ã©tÃ© initialement publiÃ© le 23/03/2021 dans <a href="https://www.lemonde.fr/blog/binaire/2021/03/23/lartisanat-de-la-science-des-donnees-avec-datacraft/">binaire</a>, blog crÃ©Ã© en janvier 2014 dans le journal <a href="https://www.lemonde.fr/blog/binaire/a-propos/">Le Monde</a> Ã  lâ€™initiative de Serge Abiteboul et de plusieurs collÃ¨gues de la SociÃ©tÃ© Informatique de France, afin de communiquer sur ce quâ€™est vraiment lâ€™informatique en tant que science et technique.</p><p>.</p><p>.</p><p>.</p><p><strong>Job : Rendre visible les lÃ©gendes des images.</strong></p><p>.</p><p>.</p><p>.</p><hr/><h1>Lâ€™artisanat de la science des donnÃ©es avec datacraft</h1><p><strong>Image here</strong>
<img src="./img/2021-03-23-binaire/Hiba.png" alt="image" title="**Courteousy of Hiba Kalache, therefore the most profound though is a beating heart (banniÃ¨re du site de datacraft)**"/>
<strong>il manque une lÃ©gende pour cette image</strong></p><p><strong>Datacraft</strong>, câ€™est quoi ce Â« machin Â» ? On est Ã  Sorbonne UniversitÃ© <strong>[1]</strong>, dans le Sorbonne Center for Artificial Intelligence, sur le campus de Jussieu, un haut lieu des sciences. Pourtant, ce nâ€™est pas un labo universitaire, mÃªme si cela y ressemble. Ã‡a tient du club, un peu du fablab. Câ€™est un espace de cotravail apprenant oÃ¹ on travaille vraiment en commun, plus que dans un espace de cotravail classique. Officiellement, câ€™est une startup. En fait, ce nâ€™est pas facile Ã  classifier, ce qui est pour moi assez positif dans le monde de la science des donnÃ©es qui se rÃ©invente en permanence.</p><p>Jâ€™ai Ã©tÃ© tentÃ© de dire que câ€™Ã©tait un Â« temple des donnÃ©es Â» tant les donnÃ©es sont au centre des prÃ©occupations de tous et toutes dans ce lieu. Mais non, les donnÃ©es ne sont pas adorÃ©es ici, elles sont questionnÃ©es, challengÃ©es. On vous parle ici de leur mise au service des entreprises et de la sociÃ©tÃ©, de Â« responsabilitÃ© sociale des donnÃ©es Â».</p><p>En fait, la vraie valeur, il faut la chercher dans le nom de lâ€™entreprise, datacraft, en franÃ§ais Â« lâ€™artisanat de la science des donnÃ©es Â» (traduction personnelle). Câ€™est tellement plus joli quâ€™en anglais, mÃªme si câ€™est certainement moins vendeur. Avec datacraft, nous sommes bien dans lâ€™artisanat, dans un savoir-faire spÃ©cifique, hors contexte industriel de masse. Nous sommes pile poil dans le compagnonnage en sciences des donnÃ©es, dans lâ€™idÃ©e de se former en faisant, en Ã©changeant, en bÃ©nÃ©ficiant de conseils dâ€™experts.</p><p>Je pense quâ€™un tel compagnonnage est particuliÃ¨rement bien adaptÃ© Ã  la science des donnÃ©es. En 2014, dans un rapport pour le gouvernement <strong>[2]</strong>, nous parlions de la nÃ©cessitÃ© de booster les formations aux sciences des donnÃ©es, en insistant sur le caractÃ¨re indispensable de projets Â« les yeux dans les yeux, de donnÃ©es en vraie grandeur Â». Depuis, de telles formations ont vu le jour et les entreprises ont souvent maintenant leurs data scientists. Mais ceux-ci souffrent dâ€™Ãªtre isolÃ©s, de ne pas pouvoir partager leurs questionnements, leurs expÃ©riences. Lâ€™image du geek qui bosse seul dans son coin est Ã  des kilomÃ¨tres de la rÃ©alitÃ© de lâ€™informatique â€“ on travaille le plus souvent en Ã©quipe â€“ et tout particuliÃ¨rement dans la science des donnÃ©es. Un beau projet en science des donnÃ©es met typiquement en jeu des compÃ©tences variÃ©es que lâ€™on trouve rarement chez une personne unique : gestion de donnÃ©es, big data, machine learning, compÃ©tence mÃ©tier, etc.</p><p><strong>Image here</strong>
<img src="./img/2021-03-23-binaire/Atelier.png" alt="image" title="**Â©datacraft, atelier computer vision au service de lâ€™imagerie mÃ©dicale**"/>
<strong>il manque une lÃ©gende pour cette image</strong></p><p>Les data scientists des entreprises adhÃ©rentes Ã  datacraft peuvent venir travailler dans un espace de cotravail oÃ¹ ils rencontreront des data scientists, leurs homologues dâ€™autres entreprises et des experts rÃ©sidence. Il ne sâ€™agit pas juste de partager de beaux bureaux et du cafÃ©.  Ils peuvent par exemple dans des ateliers pratiques Ã©changer des idÃ©es, apprendre, et partager. Et ce contexte permet aux idÃ©es dâ€™infuser entre des domaines diffÃ©rents.</p><p>Par exemple, datacraft a organisÃ© un atelier avec lâ€™INSEP (lâ€˜Institut national du sport, de lâ€™expertise et de la performance) autour de lâ€™utilisation de donnÃ©es dans le sport de haut niveau. Il sâ€™agissait dâ€™arriver Ã  construire la meilleure Ã©quipe selon le contexte, les adversaires, la mÃ©tÃ©o, etc. Il Ã©tait difficile de prÃ©voir lâ€™intÃ©rÃªt des ingÃ©s de Vinci Autoroutes sur ce sujet, pourtant, ils ont apportÃ© une expertise prÃ©cieuse.</p><p><strong>Image here</strong>
<img src="./img/2021-03-23-binaire/INSEP.png" alt="image" title="**Image: https://pixabay.com/users/clker-free-vector-images-3736/**"/>
<strong>il manque une lÃ©gende pour cette image</strong></p><p>Pas de bol, datacraft sâ€™est lancÃ©e en fÃ©vrier 2020, pas le meilleur moment pour un concept basÃ© sur un lieu de rencontre physique. Les membres ont initiÃ© des projets autour de la santÃ© et de lâ€™Ã©ducation, pour aider la sociÃ©tÃ© dans un temps de crise sanitaire grave. Je me serais aussi attendu Ã  ce quâ€™ils dÃ©couvrent les avantages considÃ©rables du travail Ã  distance, dâ€™une certaine inutilitÃ© de la rencontre physique. Pas du tout, Isabelle Hilali, fondatrice et pÃ©dÃ©gÃ¨re de datacraft, explique : Â« Pour moi, la dimension physique est essentielle, et jâ€™aimerais revenir dÃ¨s que possible au prÃ©sentiel car il est important de garder du lien. Â» Et quand jâ€™insiste sur les avantages du distanciel, elle prÃ©cise : Â« Il faut aussi le plaisir du travail. Il y a moins de plaisir Ã  collaborer Ã  distance. Â»</p><p>Quand on met des gens brillants ensemble, les initiatives fleurissent. Des membres se regroupent pour former des consortiums et rÃ©pondre Ã  des appels Ã  projets ambitieux auxquels ils nâ€™auraient pas les moyens de rÃ©pondre individuellement. Ils mettent en place des formations, des espaces dâ€™Ã©changes dans des domaines spÃ©cifiques comme les ressources humaines ou les aspects lÃ©gaux des applications de la science des donnÃ©es.</p><p>Jâ€™ai parlÃ© de datacraft Ã  des collÃ¨gues chiliens. Leur rÃ©action : un tel club serait encore plus indispensable au Chili oÃ¹ les data scientists des entreprises sont encore plus isolÃ©s quâ€™en France. Je pense que câ€™est vrai pour de nombreux pays, datacraft devrait donc sâ€™exporter ? Jâ€™ai posÃ© la question : ils ouvrent une base au Maroc en 2022. Ã€ quand le Chili ?</p><p>Postscriptum : Quand je mâ€™enthousiasme pour une startup dans binaire, il se trouve parfois un de nos trÃ¨s chers lecteurs pour questionner mon objectivitÃ©, mâ€™accuser dâ€™avoir des amis dans la startup, dâ€™y avoir investi, voire de me faire payer pour la pub. Et bien non rien de tout cela. Jâ€™ai trouvÃ© que câ€™Ã©tait une idÃ©e gÃ©niale et jâ€™ai voulu la raconter.</p><p><a href="https://fr.wikipedia.org/wiki/Serge_Abiteboul">Serge Abiteboul</a>, Inria et ENS, Paris</p><hr/><p><strong>[1]</strong> Sorbonne UniversitÃ© est une universitÃ© franÃ§aise situÃ©e Ã  Paris. Elle a Ã©tÃ© crÃ©Ã©e le 1er janvier 2018 par regroupement des universitÃ©s Paris-Sorbonne (Paris-IV) et Pierre-et-Marie-Curie (Paris-VI), elles-mÃªmes crÃ©Ã©es en 1970 et hÃ©ritiÃ¨res de lâ€™universitÃ© de Paris fondÃ©e en 1896.</p><p><strong>[2]</strong> Serge Abiteboul, FranÃ§ois Bancilhon, FranÃ§ois Bourdoncle, Stephan Clemencon, Colin De La Higuera, et al. Lâ€™Ã©mergence dâ€™une nouvelle filiÃ¨re de formation : data scientists Â», 2014 <a href="https://hal.inria.fr/hal-01092062">https://hal.inria.fr/hal-01092062</a></p>]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[Classification des mains de scribes assistÃ©e par lâ€™intelligence artificielle]]></title>
            <link>https://drkapichu.github.io/blog/egyptologie</link>
            <guid>egyptologie</guid>
            <pubDate>Thu, 04 Mar 2021 00:00:00 GMT</pubDate>
            <description><![CDATA[Article publiÃ© dans Archeologia Magazine le 04/03/2021]]></description>
            <content:encoded><![CDATA[<p>Cet article a Ã©tÃ© initialement publiÃ© le 04/03/2021 dans <a href="https://www.archeologia-magazine.com/numero-596/egypte-dernieres-decouvertes/egypte-dernieres-decouvertes.53184.php#article_53184">Archeologia Magazine</a>, magazine payant d&#x27;archÃ©ologie.</p><p>.</p><p><strong>Mettre les images avec les lÃ©gendes.</strong></p><p>.</p><hr/><h1>CLASSIFICATION DES MAINS DE SCRIBES ASSISTÃ‰E PAR Lâ€™INTELLIGENCE ARTIFICIELLE</h1><p><strong>Depuis 2019, Lâ€™Ifao et Sorbonne UniversitÃ© mÃ¨nent conjointement un programme de recherches (Ã‰CRITURES â€“ Pour une archÃ©ologie et une anthropologie des Ã©critures de lâ€™Ã‰gypte ancienne) afin de mieux comprendre les usages des diffÃ©rentes graphies Ã©gyptiennes et les acteurs impliquÃ©s. Si les textes de la vie courante (administration, lettres, littÃ©rature, sciences, textes magiques et rituels) Ã©taient inscrits en hiÃ©ratique, lâ€™Ã©criture principale des scribes Ã©gyptiens, une cursive dÃ©rivÃ©e des hiÃ©roglyphes, ces derniers demeuraient limitÃ©s Ã  des usages monumentaux et sacrÃ©s.</strong></p><h1>Identifier les mains pour connaÃ®tre les lettrÃ©s</h1><p>Les scribes, les auteurs et plus gÃ©nÃ©ralement les praticiens de lâ€™Ã©criture en Ã‰gypte ancienne, restent mal connus dâ€™autant que leurs manuscrits sur papyrus ou sur ostraca (tessons de poterie ou morceaux de calcaire taillÃ©s inscrits) furent le plus souvent anonymes. Une des tÃ¢ches des Ã©gyptologues consiste donc Ã  examiner les styles individuels dâ€™Ã©criture pour rapprocher entre eux des documents issus dâ€™une mÃªme main. Les outils de la palÃ©ographie aident Ã  Ã©tablir des comparaisons entre la forme de certains signes afin de regrouper des textes possiblement tracÃ©s par une mÃªme personne. Mais les caractÃ©ristiques Ã  prendre en compte sont nombreuses (forme gÃ©nÃ©rale du signe, nombre de traits, taille, dynamisme de lâ€™Ã©criture, mise en page, rÃ©gularitÃ©...) et constituent autant dâ€™aspects difficiles Ã  combiner et Ã  comparer, pour lâ€™Å“il et lâ€™esprit humains, lorsque le nombre de documents se multiplie. </p><h1>L&#x27;apport du Deep Learning</h1><p>Câ€™est lÃ  que les outils dâ€™intelligence artificielle, habilement mis en Å“uvre, peuvent sâ€™avÃ©rer dÃ©cisifs. Ce programme de recherche sâ€™est donc associÃ© au Sorbonne Centre of Artificial Intelligence et Ã  datacraft afin explorer les solutions que le deep learning (ou rÃ©seau de neurones) peut apporter. Une premiÃ¨re</p><p>expÃ©rience a ainsi Ã©tÃ© montÃ©e Ã  partir de documents de scribes de lâ€™Ã©poque ramesside (XIII e -XI e siÃ¨cles avant notre Ã¨re). Des jeux de donnÃ©es provenant du British Museum, du Museo Egizio de Turin et de lâ€™Institut franÃ§ais dâ€™archÃ©ologie orientale, constituÃ©s de photos numÃ©riques dâ€™ostraca et de papyrus publiÃ©s, ont Ã©tÃ© collectÃ©s. RÃ©alisÃ©e avec lâ€™Ã©quipe Data science de Vinci Autoroutes qui travaille rÃ©guliÃ¨rement avec datacraft, une Ã©tape de prÃ©paration des donnÃ©es a Ã©tÃ© nÃ©cessaire avant de prÃ©senter ces images numÃ©riques au rÃ©seau de neurones. GrÃ¢ce au logiciel de Vinci, les Ã©gyptologues ont annotÃ© les documents dont les scribes-rÃ©dacteurs Ã©taient connus avec certitude. Il fut ensuite possible de classer automatiquement les images non-annotÃ©es grÃ¢ce au rÃ©seau de neurones, ce dernier identifiant si telle ou telle image appartient Ã  une main dÃ©jÃ  connue. Une autre voie explorÃ©e se fonde plus directement sur les signes Ã©gyptiens utilisÃ©s dans les documents non classÃ©s. Elle consiste Ã  utiliser le rÃ©seau de neurones pour regrouper les textes dont les signes dâ€™une Ã©criture similaire, ce qui permettra Ã  terme dâ€™identifier de nouveaux scribes potentielsâ€¦</p><p><strong>ChloÃ© Ragazzoli</strong>, Sorbonne UniversitÃ©, <strong>Florence Albert</strong>, Ifao, <strong>Xavier Lioneton</strong>, datacraft, <strong>Amir Nakib</strong>, Vinci, dans le cadre dâ€™une collaboration au sein du club datacraft</p>]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[datacraft - un club dÃ©diÃ© Ã  la data science et lâ€™Intelligence Artificielle]]></title>
            <link>https://drkapichu.github.io/blog/datacraft</link>
            <guid>datacraft</guid>
            <pubDate>Mon, 15 Feb 2021 00:00:00 GMT</pubDate>
            <description><![CDATA[Article publiÃ© dans Visionary le 15/02/2021]]></description>
            <content:encoded><![CDATA[<p>Cet article a Ã©tÃ© initialement publiÃ© le 15/02/2021 dans <a href="https://visionarymarketing.com/fr/2021/02/datacraft-data-science-et-ia/?mc_cid=a430616615&amp;mc_eid=0bd4a33d6d">Visionary</a>, site d&#x27;infos des marketeurs et innovateurs visionnaires depuis 1996.</p><p>.</p><p>.</p><p>.</p><p><strong>Job : Voir si possible d&#x27;inclure l&#x27;audio de l&#x27;interview d&#x27;Isabelle.</strong></p><p><strong>Job : Travailler la prÃ©sentation pour montrer que c&#x27;est une vidÃ©o.</strong></p><p><strong>Job : Rendre visible les lÃ©gendes des images.</strong></p><p><strong>Job : Changer le style des citations.</strong></p><p>.</p><p>.</p><p>.</p><hr/><h1>Datacraft : un club dÃ©diÃ© Ã  la data science et lâ€™Intelligence Artificielle</h1><p>Un club Data Science et IA ? LÃ  oÃ¹ beaucoup veulent absolument quâ€™on remplace les humains par des robots, les experts de lâ€™IA dÃ©montrent la supÃ©rioritÃ© des Ã©changes humains. Car il y avait un besoin dâ€™Ã©change dans la communautÃ© de la data science et <a href="https://www.linkedin.com/in/isabelle-hilali-82b5111/">Isabelle Hilali</a>, CEO et fondatrice de Datacraft, que <a href="https://visionarymarketing.com/fr/2016/09/big-data-sante-combinaison-necessaire/">nous avions dÃ©jÃ  interviewÃ©e</a> ici il y a quelques annÃ©es, lâ€™avait pressenti. Elle nâ€™a pas hÃ©sitÃ© Ã  lancer son club data science en plein milieu de la crise du Covid et a dÃ©montrÃ©, mÃªme en ces temps difficiles que tout est possible. Elle a dÃ©montrÃ© Ã©galement que la nÃ©cessitÃ© de se parler, y compris pour les experts de lâ€™IA et de la data science, est plus forte que jamais. Retour sur la crÃ©ation dâ€™un club hors du commun, oÃ¹ se dessine collaborativement le futur de vos logiciels. </p><h2>Datacraft : un club data science et IA installÃ© au cÅ“ur de La Sorbonne</h2><p><img src="./img/2021-02-15-datacraft/datacraft-scai.png" alt="image" title="Jâ€™ai rencontrÃ© Isabelle Hilali dans ses locaux du SCAI (Sorbonne Center for Artificial Intelligence) qui hÃ©berge Datacraft, le club de la data science et de lâ€™IA quâ€™elle a crÃ©Ã©"/>
<strong>il manque une lÃ©gende pour cette image</strong></p><blockquote><p>&quot;Jâ€™ai observÃ© que lâ€™univers de la data science et des data scientists est un domaine sur lequel il faut apprendre tout le temps et oÃ¹ tout va extrÃªmement vite.&quot;
Isabelle Hilali â€“ Datacraft</p></blockquote><p>Â« En data science, il est vraiment compliquÃ© dâ€™Ãªtre Ã  la pointe en termes de compÃ©tences. Câ€™est un univers oÃ¹ lâ€™on a besoin de partager. On a toujours lâ€™image du geek qui est seul derriÃ¨re son micro, mais en fait, si on veut Ãªtre bon, il faut croiser les donnÃ©es et Ãªtre imaginatif Â» explique Isabelle.</p><p>Câ€™est un univers sur lequel il y a beaucoup de libertÃ© puisque ce sont des mÃ©tiers trÃ¨s demandÃ©s alors que trop peu de bonnes compÃ©tences sont disponibles. Les data scientists peuvent donc quelque peu Â« imposer Â» la faÃ§on dont ils ont envie de travailler. Et ils ont envie de travailler de maniÃ¨re flexible.</p><blockquote><p>&quot;Lâ€™idÃ©e, câ€™Ã©tait dâ€™avoir un lieu qui donne envie de collaborer&quot;</p></blockquote><p>Le Centre dâ€™intelligence artificielle de la Sorbonne a Ã©tÃ© imaginÃ© pour permettre de se retrouver pour collaborer. Câ€™est un lieu ouvert. Et câ€™est lÃ  que Datacraft sâ€™est implantÃ©, entre la tour de Jussieu et le jardin des plantes.</p><iframe width="85%" height="500px" src="https://www.youtube.com/embed/0xtPrTo-13o" alt="PrÃ©sentation de datacraft par Isabelle" title="YouTube video player" frameBorder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe><h2>Un portrait robot du data scientist ? Impossible tant ce mot recouvre des rÃ©alitÃ©s diffÃ©rentes</h2><p>Jâ€™aimerais bien faire un portrait robot de la <a href="https://visionarymarketing.com/fr/2015/07/data-scientist/">data scientist</a>, mais il nâ€™y en a pas beaucoup pour lâ€™instant â€¦ Alors jâ€™ai commencÃ© par le data scientist au sens large.</p><blockquote><p>&quot;Il nâ€™y a pas de portrait robot du data scientist. Ce mot est utilisÃ© un peu Ã  tort et Ã  travers. Il recouvre diffÃ©rentes rÃ©alitÃ©s&quot;</p></blockquote><p>Il y a Ã©galement le data ingÃ©nieur, le data scientist, le data analyst. Il y a besoin de prÃ©parer les donnÃ©es, de dÃ©velopper des modÃ¨les, dâ€™intÃ©grer aussi tout cela dans le systÃ¨me dâ€™information.</p><p>Certains ont une formation assez classique, une grande Ã©cole dâ€™ingÃ©nieurs ou une grande Ã©cole de math et dâ€™informatique. Mais dâ€™autres ont fait de la musique et ensuite se sont formÃ©s Ã  la datascience.</p><p><img src="./img/2021-02-15-datacraft/datacraft-scai.png" alt="image" title="MÃªme masquÃ©s, les ateliers datacraft de data science sont un moment privilÃ©giÃ© dâ€™Ã©change et de travail"/>
<strong>il manque une lÃ©gende pour cette image</strong></p><p>Le bon data scientist, qui va Ãªtre performant dans une organisation, doit Ãªtre curieux. Il doit Ãªtre ouvert Ã  lâ€™organisation dans laquelle il est, pour comprendre la situation et Ã©viter de construire des modÃ¨les abstraits qui ne serviront Ã  rien. Il doit comprendre les problÃ©matiques en allant chercher des donnÃ©es, en faisant de lâ€™apprentissage machine, en dÃ©veloppant des modÃ¨les, en sâ€™interrogeant sur la meilleure faÃ§on dâ€™aider Ã  la connaissance, Ã  la prise de dÃ©cision.</p><blockquote><p>&quot;Pour moi, le bon data scientist est quelquâ€™un dâ€™ouvert et de collaboratif, et qui a des compÃ©tences en mathÃ©matiques et en informatique, ou au moins la capacitÃ© Ã  travailler sur ces sujets&quot;</p></blockquote><h2>La nÃ©cessitÃ© dâ€™apprendre dans le domaine de la data science</h2><p>Le besoin principal sur lequel jâ€™avais envie de travailler, Ã©tait la nÃ©cessitÃ© dâ€™apprendre en permanence.</p><p>Il existe bien des formations en ligne, des formations physiques, des livres, des communautÃ©s pour faire de la recherche. Mais il nâ€™existait pas de lieu physique oÃ¹ partager les choses.</p><p><strong>Jâ€™ai Ã©tÃ© assez inspirÃ©e par le modÃ¨le du compagnonnage</strong>, câ€™est une chouette faÃ§on dâ€™apprendre, avec les autres, en le revisitant un peu, car dans notre modÃ¨le, chacun apprend aux autres, il nâ€™y a pas de maÃ®tre ni dâ€™Ã©lÃ¨ve. Chacun est maÃ®tre sur un bout de sujet.</p><p>Je me suis dit quâ€™il faudrait quâ€™il y ait des lieux qui permettent aux gens un Ã©change de bonnes pratiques et qui soient pensÃ©s pour Ã§a. Et en mÃªme temps qui dÃ©veloppent la collaboration et la rÃ©flexion sur ce quâ€™on fait, quelles limites on veut donner quand on dÃ©veloppe de lâ€™intelligence artificielle.</p><blockquote><p>&quot;Notre volontÃ© avec Datacraft Ã©tait de crÃ©er ce rÃ©seau de lieux pour se retrouver entre experts pour un Ã©change de bonnes pratiques&quot;</p></blockquote><h2>Le lancement de Datacraft, le club data science et IA</h2><p>Jâ€™ai lancÃ© DataCraft en janvier 2020, avec le groupe Accor et lâ€™Insep, les deux premiers membres qui mâ€™ont fait confiance, et dans de supers locaux dans le Marais.</p><p>Tout cela a pris forme dÃ©but fÃ©vrier avec lâ€™ouverture des locaux, avec Ã©galement notre systÃ¨me de rÃ©sidence oÃ¹ lâ€™on accueille Ã  la fois des chercheurs, et des freelances qui font partie de la communautÃ©, qui ne paient pas dâ€™adhÃ©sion, mais qui donnent du temps Ã  la communautÃ©.</p><p>Et puis tout a fermÃ© un mois plus tard avec le confinement â€¦</p><p>Le concept Ã©tant de mettre les gens ensemble et dâ€™avoir cette complÃ©mentaritÃ© avec ce qui existe en digital, jâ€™ai pensÃ© quâ€™il allait falloir fermer.</p><p>Et puis finalement, on avait encore davantage besoin de cet Ã©change de bonnes pratiques, de cette solidaritÃ© entre experts et de cette crÃ©ativitÃ©.</p><p>La communautÃ© a Ã©normÃ©ment grossi. Nous sommes passÃ©s de 80 a plus de 500 en fin de confinement, en fÃ©dÃ©rant des gens qui avaient envie de sâ€™entraider.</p><h2>Un club data science : comment Ã§a marche ?</h2><p>Par exemple, un membre va communiquer sur le dÃ©veloppement dâ€™une application en Python, alors quâ€™il a lâ€™habitude de faire sur <a href="https://help.adobe.com/en_US/air/build/index.html">Adobe Air</a>, et poser la question si dâ€™autres membres ont dÃ©jÃ  fait cela pour un type dâ€™applications, pour un tableau de bord par exemple.</p><p>La demande est lancÃ©e dans la communautÃ©, des membres vont rÃ©pondre et au lieu que ce soit deux personnes qui se parlent, on en profite pour organiser un atelier, virtuellement pendant le Covid, oÃ¹ les gens vont partager leurs bonnes pratiques. Souvent, Ã  la fin de lâ€™atelier, un atelier suivant se dessine de par les Ã©changes qui ont eu lieu sur par exemple une bibliothÃ¨que que les membres nâ€™avaient jamais pensÃ© Ã  utiliser comme Ã§a.</p><p>Puis, il y a eu le premier dÃ©confinement et nous avons recommencÃ© Ã  faire des ateliers en physique.</p><p>Nous avons organisÃ© un atelier, par exemple, sur les donnÃ©es du sport de haut niveau, avec des problÃ©matiques telles quâ€™aider un entraÃ®neur Ã  optimiser son Ã©quipe, Ã  choisir lâ€™Ã©quipe qui sera la plus performante en fonction des adversaires, en fonction de donnÃ©es, de mÃ©tÃ©o ou de tout cet environnement.</p><p>Câ€™est un prÃ©texte. Sur un projet comme Ã§a, des membres vont venir pendant deux jours travailler ensemble, des gens de lâ€™Insep, de Vinci Autoroutes, dâ€™un labo pharmaceutique, dâ€™une petite startup qui va travailler sur des donnÃ©es des rÃ©seaux sociaux, par exemple. Et tous ces gens vont travailler ensemble pendant deux jours.</p><p>Contrairement Ã  un hackathon, notre objectif nâ€™est pas de faire un prototype au bout de deux jours qui souvent, en outre, nâ€™est pas trÃ¨s bon.</p><blockquote><p>&quot;Notre seule volontÃ© est quâ€™Ã  la fin des deux jours ou de la demi-journÃ©e, les participants repartent en se disant  Â» Câ€™est gÃ©nial, jâ€™ai appris telle chose Â»&quot;</p></blockquote><p>Câ€™est Ã§a notre objectif, un Ã©change de bonnes pratiques, oÃ¹ mÃªme les Â« super experts Â» apprennent quelque chose.</p><p>Cela va bien au delÃ  bien sÃ»r. De nombreux partenariats se nouent, quâ€™on nâ€™aurait jamais imaginÃ©. Un partenariat entre Vinci Autoroutes et le sport de haut niveau par exemple.</p><p>Ou encore une startup qui travaille sur les donnÃ©es des rÃ©seaux sociaux en santÃ©, qui va dÃ©couvrir une expertise complÃ©mentaire chez un membre de Datacraft, et envisager de monter un gros projet europÃ©en sur les fakenews mÃ©dicales.</p><p>Ou encore Danone, par exemple, qui est en train de rÃ©diger sa <a href="https://visionarymarketing.com/fr/glossaire/marketing-ethique/">charte</a> sur lâ€™utilisation responsable des donnÃ©es, qui la rÃ©alise avec dâ€™autres membres qui lâ€™ont dÃ©jÃ  fait pour lâ€™Ã©crire ensemble.</p><h2>Lâ€™avenir pour Datacraft, le club de la data science</h2><p>Lâ€™idÃ©e Ã©tait dâ€™avoir un lieu qui donne envie de collaborer et de se poser des questions sur la faÃ§on dont on travaille la data, quelle responsabilitÃ© on a envers la sociÃ©tÃ©.</p><p>Lâ€™idÃ©e Ã©tait aussi dâ€™avoir dans Paris un lieu avec un jardin, des plantes, qui favorise cette collaboration et cette rÃ©flexion.</p><p>Nous sommes au Centre dâ€™intelligence artificielle de la Sorbonne, et cela fait Ã©normÃ©ment de sens. Le Centre dâ€™intelligence artificielle de la Sorbonne a Ã©tÃ© imaginÃ© pour permettre Ã  tout lâ€™Ã©cosystÃ¨me de Sorbonne universitÃ©s, le Museum dâ€™histoire naturelle, lâ€™IRCAM en musique, la fac de mÃ©decine, de se retrouver pour collaborer.</p><p>Câ€™est un lieu ouvert oÃ¹ les entreprises sont les bienvenues. Etre hÃ©bergÃ©s ici, Ã  cÃ´tÃ© du Jardin des Plantes, est complÃ¨tement en phase avec nos valeurs.</p><p><strong>Dans le futur, il y aura dâ€™autres bases datacraft</strong> qui seront toutes imaginÃ©es autour de ce concept de collaboration et de responsabilitÃ©.</p><h2>Le Covid : crise ou opportunitÃ© ?</h2><p>Cela a Ã©tÃ© aussi une source de crÃ©ativitÃ© pour nous, Cela nous a permis de faire des choses Ã  distance, et dâ€™avoir, par exemple, des personnes en Ouganda qui nous ont demandÃ© de participer Ã  un atelier. Nous nâ€™aurions pas pu faire ce genre de choses aussi rapidement.</p><p>Et puis, Ã§a nous a montrÃ© ce besoin de solidaritÃ© et dâ€™Ã©change de bonnes pratiques.</p><blockquote><p>&quot;MÃªme si on espÃ¨re bien sÃ»r que Ã§a durera pas trop longtemps, cette pÃ©riode a finalement encore renforcÃ© nos valeurs&quot;</p></blockquote>]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[TÃ©lÃ©consultation - une porte dâ€™entrÃ©e dans le parcours de soins ?]]></title>
            <link>https://drkapichu.github.io/blog/Teleconsultation</link>
            <guid>Teleconsultation</guid>
            <pubDate>Fri, 27 Nov 2020 00:00:00 GMT</pubDate>
            <description><![CDATA[Article publiÃ© dans Pharmaceutiques le 27/11/2020]]></description>
            <content:encoded><![CDATA[<p>Cet article a Ã©tÃ© initialement publiÃ© le 27/11/2020 dans <a href="https://pharmaceutiques.com/actualites/nouvelles-technologies/teleconsultation-une-porte-dentree-dans-le-parcours-de-soins/">Pharmaceutiques</a> journal spÃ©cialisÃ© dans les secteurs de la santÃ© et du mÃ©dicament.</p><hr/><h1>TÃ©lÃ©consultation : une porte dâ€™entrÃ©e dans le parcours de soins ?</h1><h2>Une Ã©tude menÃ©e par la plateforme de tÃ©lÃ©mÃ©decine Qare, en partenariat avec datacraft et Ekimetrics, analyse avec prÃ©cision 300 000 tÃ©lÃ©consultations rÃ©alisÃ©es en janvier 2019 et juillet 2020.</h2><p>Quel est le profil des utilisateurs de la tÃ©lÃ©consultation ? Et qui a profitÃ© en prioritÃ© de lâ€™assouplissement du cadre rÃ¨glementaire dÃ©cidÃ© en mars dernier en phase dâ€™entrÃ©e dans la pandÃ©mie de Covid19 ? Au moment oÃ¹ les syndicats de professionnels de santÃ© discutent, dans le cadre conventionnel, des nouvelles modalitÃ©s de la tÃ©lÃ©mÃ©decine, il apparait essentiel de bien connaitre la structure de â€ consommationâ€ de cette nouvelle forme de recours aux soins. Câ€™est dans ce but que la plateforme Qare, lâ€™un des principaux leaders de la tÃ©lÃ©consultation, a menÃ© une enquÃªte dÃ©taillÃ©e, auprÃ¨s de 2050 praticiens, 180 150 patients, et sur la base de 300 000 tÃ©lÃ©consultations. Â« Notre enquÃªte porte sur une pÃ©riode large, de janvier 2019 Ã  juillet 2020, prÃ©cise le Dr Julie Salomon, directrice mÃ©dicale adjointe de Qare. Il faut Ã©galement tenir compte du fait quâ€™il ne nous a pas Ã©tÃ© possible de distinguer les profils de consommation avant et aprÃ¨s lâ€™arrivÃ©e de la pandÃ©mie. Â» En raison de lâ€™explosion du nombre de tÃ©lÃ©consultations Ã  partir de mars, par rapport Ã  la pÃ©riode prÃ©cÃ©dente, la comparaison statistique nâ€™aurait pas Ã©tÃ© pertinente. Par ailleurs, les donnÃ©es proviennent des tÃ©lÃ©consultations opÃ©rÃ©es par Qare : or, lâ€™entreprise a fait son entrÃ©e sur le marchÃ© dÃ¨s janvier 2017, par le biais dâ€™une convention avec lâ€™ARS des FranÃ§ais de lâ€™Ã©tranger. Â« Nous avons initiÃ© lâ€™outil avec les FranÃ§ais installÃ©s hors de France, avant de pouvoir dÃ©velopper ce qui est notre coeur de mÃ©tier, lâ€™offre de soin pour les franÃ§ais du territoire national, ajoute Julie Salomon. Cet engagement, antÃ©rieur au cadre rÃ¨glementaire posÃ© en janvier 2019, explique la diversitÃ© de notre panel dâ€™utilisateurs.Â» </p><h2>Des utilisateurs jeunes, un besoin aigu de santÃ©</h2><p>Ces rÃ©serves Ã©tant posÃ©es, lâ€™Ã©tude livre des rÃ©sultats inÃ©dits et particuliÃ¨rement intÃ©ressants. Pour la rÃ©aliser, Qare sâ€™est appuyÃ© sur lâ€™expertise de deux partenaires : datacraft, une startup avec un modÃ¨le de Club qui permet un Ã©change de bonnes pratiques entre experts de la donnÃ©e, et le leader europÃ©en en data science Ekimetrics. Â« Le premier enseignement, câ€™est que la tÃ©lÃ©consultation est une solution principalement utilisÃ©e par une population jeune et plutÃ´t urbaine, note Soline Aubry, lead du projet pour Ekimetrics. Les patients ont en moyenne 35 ans, contre 41 ans pour lâ€™ensemble de la population franÃ§aise. Et 60% vivent dans lâ€™une des dix plus grandes zones urbaines. Â» Le mode de consommation est Ã©galement rÃ©vÃ©lateur : le pic de tÃ©lÃ©consultation se situe plutÃ´t tÃ´t, avant 10 heures du matin, et plutÃ´t en dÃ©but de semaine. Â« Cela traduit sans doute un besoin de prise en charge rapide, dÃ¨s lâ€™ouverture des cabinets, analyse Julie Salomon. Le phÃ©nomÃ¨ne Ã©tait moins marquÃ© durant la phase de confinement. Â» Quels mÃ©decins sont consultÃ©s en prioritÃ© ? Dâ€™abord des mÃ©decins gÃ©nÃ©ralistes, pour 63% des consultations. Les 37% de consultation chez les spÃ©cialistes sâ€™effectuent en prioritÃ© les dermatologues, les pÃ©diatres et les psychiatres, trois spÃ©cialitÃ©s en forte tension dÃ©mographique.</p><h2>40% de fidÃ©lisation au mÃ©decin tÃ©lÃ©consultÃ©</h2><p>UtilisÃ©e majoritairement pour des affections dites â€courantesâ€ (cystite, rhume, gastro-entÃ©rite, Ã©tat grippalâ€¦), la tÃ©lÃ©consultation (chez Qare) est un outil, selon les auteurs de lâ€™Ã©tude, pour offrir une rÃ©ponse en urgence face Ã  un besoin de santÃ© aigu. Et il permet, Â« dans 99% des cas Â», dâ€™Ã©viter un dÃ©placement inutile chez le mÃ©decin. Â« Câ€™est une donnÃ©e importante, car elle laisse entendre que la tÃ©lÃ©consultation pourrait permettre de dÃ©sengorger les cabinets et de faciliter la prise en charge des soins non programmÃ©s Â», estime Julie Salomon. Dâ€™autres chiffres rÃ©vÃ©lÃ©s par Ekimetrics montrent par ailleurs que si 86% des patients et des mÃ©decins ne se connaissaient pas au moment du premier rendez-vous, 40% des patients ont pris le second rendez-vous avec le mÃªme mÃ©decin. Â« La tÃ©lÃ©consultation peut donc Ãªtre lâ€™occasion pour les patients dâ€™entrer dans le parcours de soins Â» ajoute Isabelle Hilali, fondatrice et dirigeante de datacraft.</p><h2>Lâ€™enjeu des soins chroniques</h2><p>PremiÃ¨re Ã©tape dâ€™une Ã©tude au long cours, cette enquÃªte sera prolongÃ©e, dans les mois Ã  venir, par de nouveaux questionnements. Qui consulte quelles spÃ©cialitÃ©s ? Comment se profilent les parcours de tÃ©lÃ©consultation en fonction des typologies de territoires ? Lâ€™usage de la tÃ©lÃ©consultation dÃ©colle-t-il dans les zones de faible densitÃ© gÃ©ographique ? Et les seniors et les malades chroniques sâ€™y engagent-ils ? Enfin, comment la pandÃ©mie modifie-t-elle les modalitÃ©s de recours Ã  la consultation Ã  distance ? Les enjeux dâ€™avenir de la tÃ©lÃ©mÃ©decine se profilent derriÃ¨re ces questions : pour sâ€™imposer dÃ©finitivement dans les usages des patients et les pratiques des mÃ©decins, elle devra nÃ©cessairement contribuer Ã  la fluiditÃ© des parcours de soins pour les malades chroniques.</p>]]></content:encoded>
        </item>
    </channel>
</rss>