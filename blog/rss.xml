<?xml version="1.0" encoding="utf-8"?>
<rss version="2.0" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:content="http://purl.org/rss/1.0/modules/content/">
    <channel>
        <title>datacraft blog Blog</title>
        <link>https://drkapichu.github.io/blog</link>
        <description>datacraft blog Blog</description>
        <lastBuildDate>Wed, 02 Mar 2022 00:00:00 GMT</lastBuildDate>
        <docs>https://validator.w3.org/feed/docs/rss2.html</docs>
        <generator>https://github.com/jpmonette/feed</generator>
        <item>
            <title><![CDATA[A list of possible styles (stolen everywhere)]]></title>
            <link>https://drkapichu.github.io/blog/html</link>
            <guid>html</guid>
            <pubDate>Wed, 02 Mar 2022 00:00:00 GMT</pubDate>
            <description><![CDATA[Ceci est une aide-mémoire pour liste les possibilités de styles dans du MarkDown]]></description>
            <content:encoded><![CDATA[<p>Ceci est un lien vers un site qui liste les balises HTML avec des exemples (!!) : <a href="https://developer.mozilla.org/fr/docs/Web/HTML/Element/Img">https://developer.mozilla.org/fr/docs/Web/HTML/Element/Img</a></p><p>Essentially stupid thing you can find anywhere on the web because they&#x27;re basics. But you&#x27;re lazy man!!</p><h1>Ceci est une liste avec un titre</h1><h2>Etre un bénévole Data For Good</h2><p>Mais en pratique être bénévole cela veut dire : </p><ul><li>Faire partie d&#x27;une communauté tech engagée</li><li>Participer aux saisons d&#x27;accélération</li><li>... Bref, Data For Good est une communauté libre et indépendante, tu peux proposer ce que tu veux !</li></ul><p>Pour plus de détails tu peux lire la page <a href="https://dataforgood.slite.com/p/channel/F9UR6bhuYCPAtvfLDje8Zc/notes/t1KTZaDgs">suivante</a>. </p><hr/><h2>Le Slack Data For Good</h2><p>Slack est un outil de messagerie communautaire, c&#x27;est aujourd&#x27;hui le coeur de la communauté où se passe les discussions entre volontaires, l&#x27;organisation autour des projets, et où se partagent évènements, offres d&#x27;emploi, liens et actualités de l&#x27;association. Pour rejoindre le Slack, c&#x27;est simple il suffit de remplir le questionnaire ci-dessus. </p><p><img src="./img/2022-03-02-CSSStyle/slack.png" alt="slack"/></p><hr/><h1>Internal links</h1><p>Visitez la page <a href="/blog">🔥 Blog</a> pour découvrir nos accélérations depuis 2014.</p>]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[This is a test for the actions]]></title>
            <link>https://drkapichu.github.io/blog/testou</link>
            <guid>testou</guid>
            <pubDate>Mon, 28 Feb 2022 00:00:00 GMT</pubDate>
            <description><![CDATA[C'est un test pour faire fonctionner l'action GitHub]]></description>
            <content:encoded><![CDATA[<p>(setq markdown-css-paths &#x27;(&quot;./custom_blog.css&quot;))</p><p>My fucking test</p><p>This is a fucking new post with GitHub automatic Actions!</p><p>.</p><p>.</p><p>.</p><p><strong>Cet article est payant. TOutefois je l&#x27;ai sur mon ordi, dans les documents de l&#x27;égypto, mais il est particulièrement long et structuré d&#x27;une manière que je ne pourrais pas reproduire en markdown.</strong></p><p><strong>Que faire ?</strong>
.</p><p>.</p><p>.</p><hr/><h1>Un titre</h1><p><img src="./img/2022-02-28-GitHubActions/Gozilla6.jpg" alt="image" title="**Some text**"/></p><p>And here I write some text to have something to commit!!!</p><p>This is a new day, a new year, a new life.
Another brick in the wall..
Tada</p><link href="./custom_blog.css" rel="stylesheet"/><p class="my_style">Ceci est un test </p><p class="red">red fucking text</p><p>&lt;my_style&gt;this is a test&lt;/my_style&gt;</p><script src="https://gist.github.com/ollytheninja/8498790.js"></script><hr/><abbr> this is a test </abbr>]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[Few Shot Learning - application de la méthode iPET]]></title>
            <link>https://drkapichu.github.io/blog/draft</link>
            <guid>draft</guid>
            <pubDate>Fri, 04 Feb 2022 00:00:00 GMT</pubDate>
            <description><![CDATA[Draft of the first blog]]></description>
            <content:encoded><![CDATA[<p>(<a href="https://numenta.com/blog/2019/08/30/case-for-sparsity-in-neural-networks-part-1-pruning">source</a> de l&#x27;image de présentaion)</p><hr/><h2>Qu’est ce que le Few Shot Learning (FSL) ? - titre alternatif : Sujet du jour : le Few Shot Learning (FSL)</h2><p>Il est bien connu que la puissance des méthodes de Machine Learning supervisées, et plus particulièrement de Deep Learning avec les réseaux de neurones, depuis le début des années 2000, a reposé sur la constitution de <strong>grands jeux de données labellisés</strong>. Deux éléments sont importants ici : ‘grands’ et ‘labellisés’.</p><p>Pour le premier point, ça représente par exemple des milliers, voire des millions d’images pour la Computer Vision et des millions d’ensembles de phrases pour le NLP. Concernant le second point, il signifie qu’au cours de son apprentissage, l’ordinateur compare son évaluation des données avec le label qu’un intervenant humain a associé à chaque donnée.</p><p>Dans le cas du <strong>Few Shot Learning (FSL)</strong>, les chercheurs veulent créer des méthodes capables d’apprendre avec peu de données, i.e. des dizaines ou des centaines, ce qui représente un gain de temps et d’énergie, tout en conservant des performances équivalentes aux modèles traditionnels bien sûr. C’est pourquoi en français on parle d’<strong>apprentissage frugal</strong>. Toutefois, en pratique les méthodes de FSL prennent un modèle traditionnel, pré-entraîné sur un grand nombre de données, et elles le spécialisent sur le cas d’usage via une courte phase d’apprentissage sur le petit jeu de données à disposition ; c’est du fine-tuning. Mais en plus, le Few Shot c’est une méthode qui va au-delà des méthodes traditionnelles, elle permet de faire du semi-supervisé, c’est ce qu’on va voir avec le cas d’usage.</p><h2>Le cas d’usage - titre alternatif : C’est quoi le problème ?!</h2><p>Ekimetrics s’est intéressé à l’apprentissage frugal pour exploiter les énormes jeux de données des petits commentaires quotidiens sur internet, avec une problématique de gain de temps… De la frugalité avec des énormes jeux de données ? On vous explique !</p><p>Mieux que le seul nombre d’étoiles d’un restaurant ou d’un hôtel, il s’agit de prendre en compte les avis dans les tweets, les posts, les brèves… qui sont par essence des données non labellisées et de les exploiter. L’annotation humaine de ces avis est inenvisageable. Ça coûterait trop cher, ça prendrait trop de temps, et il faudrait recommencer tous les jours pour suivre l’évolution du sentiment. En l&#x27;occurrence, pour la recherche d’Ekimetrics, le sujet d’étude porte sur des commentaires de restaurants.</p><p>Mais si la machine était capable d’évaluer les commentaires, à 2 Gigahertz, tout de suite le problème serait réglé. C’est là que le Few Shot, en utilisant la méthode PET, peut devenir utile.</p><p>Dans la suite, nous vous présentons la méthode PET, comment l’utiliser dans le cadre du FSL et enfin, comment Ekimetrics l’utilise sur les avis des consommateurs.</p><h2>PET qu’est ce que c’est ?</h2><p><strong>PET</strong> est l’acronyme de ‘<strong>Pattern Exploiting Training</strong>’. La méthode repose sur un ensemble fixe et prédéfini de <strong>patterns</strong> et de <strong>verbalizers</strong> et un <strong>Pre-trained Language Model</strong> a.k.a. <strong>PLM</strong>. Les patterns sont les phrases à trou (“It was…”, “Just…!”, “All in all, it was…”, “In summary, the restaurant is…”) et les verbalizers sont les mots qui peuvent compléter ces phrases et auxquels sont associées des notes chiffrées. On commence à retrouver les nombres que l’ordinateur aime tant !</p><p>Concrètement, reprenons notre exemple des évaluations des restaurants, la méthode consiste à :</p><ul><li>prendre un commentaire,</li><li>y associer aléatoirement un pattern,</li><li>soumettre le tout au PLM qui va le compléter en choisissant un verbalizer.</li></ul><p><img src="./img/2022-02-04-MindshakeTime/PET.png" alt="image" title="Schema of a basic PET"/>{:.image-left}</p><p>Par exemple (voir Fig. 1), avec le commentaire “Best pizza ever!”, on construit la phrase à trou : “Best pizza ever! It was … .” que le PLM va compléter avec ‘great’ avec une confiance de 0.8, sachant que ce mot est noté +1.</p><h2>FSL + PET : première application aux avis internet</h2><p>Revenons à la masse brute des avis des consommateurs sur internet. <strong>PET est la méthode</strong> pour associer une note à un commentaire, le <strong>FSL est le moyen</strong> de traiter automatiquement tout le jeu de données, et le travail de l’algorithme se fait en deux étapes.</p><p>Dans un premier temps, on labellise un petit nombre de commentaires, une centaine par exemple, ce qui signifie qu’on associe une paire pattern plus verbalizer à ces commentaires, et on finetune le PLM avec cette centaine. Puis, une fois le PLM spécialisé, on le laisse labelliser tout le reste du jeu de données, automatiquement. Ça en fait une méthode semi-supervisée d’analyse de sentiment des commentaires.</p><p>Cependant, cette application basique présente des limites. D’une part, le verbalizer donné par le PLM peut ne pas être le plus adapté au commentaire et, d’autre part, c’est très ambitieux de spécialiser le PLM une fois sur une centaine d’exemples pour ensuite en traiter des dizaines de milliers ou plus. C’est pourquoi les chercheurs ont développé une méthode de distillation qui augmente la robustesse de PET, c’est la méthode <strong>iPET : iterative PET</strong>.</p><h2>i(terative)PET : une méthode de distillation astucieuse</h2><p>Une image peut valoir mille mots…</p><p><img src="./img/2022-02-04-MindshakeTime/iPET.png"/></p><p>… Mais quelques mots seront quand même nécessaires pour expliquer cette image !</p><p>Tout d’abord, le schéma de gauche sur la figure présente l’adaptation de PET qui permet d’obtenir le label le plus adapté au commentaire… en moyenne. En effet, il s’agit ‘simplement’ de <strong>faire travailler des méthodes PET indépendantes en parallèle</strong> (trois sur le schéma). Les trois cellules ont le même PLM au départ, et elles travaillent sur les mêmes commentaires, mais avec des patterns différents. Dans la phase d’entraînement sur les données labellisées, les PLMs se spécialisent différemment. Puis, durant la phase de travail, pour un même commentaire ils produisent des <strong>paires pattern-verbalizers</strong> (appelées <strong>PVPs</strong> sur le schéma) indépendamment les uns des autres ; possiblement les mêmes, mais pas avec les mêmes probas. Enfin, <strong>en sortie</strong> ces (trois) labels sont utilisés pour calculer <strong>un soft-label</strong>, i.e. un <strong>label moyen</strong>.</p><p>Ensuite, sur la droite est présenté le caractère itératif de la méthode iPET. Elle consiste à diviser le jeu labellisés sur plusieurs itérations (indiquées par les exposants allant de 0 à k) et à diviser encore à chaque itération entre plusieurs méthodes parallèles (indiquées par les indices allant de 0 à 4). Mais attention, chacun des quatre modèles ici fait du soft-labelling comme présenté à gauche de la figure, c’est-à-dire qu’ils contiennent plusieurs méthodes en parallèle.</p><p>Donc, si l’on suppose que l’on part pour trois itérations, l’information labellisée est distillée de la manière suivante. À l’itération 0 sur le schéma, on prend un tiers des données labellisées, et on fournit un quart de ces données à chaque modèle pour le finetuner, avant de prendre un tiers des données à labelliser et d’en fournir un quart à chaque modèle pour soft-labellisation. Ce qui constitue la fin de la première itération.</p><p>À la deuxième itération - itération 1 sur le schéma, on commence à nouveau par un phase de fine-tuning, mais avec un jeu de données labellisées constitué pour partie des données annotées par un être humain (le deuxième tiers), et pour partie de données soft-labellisées. Toutefois, on fait attention à ce qu’un modèle ne s’entraîne pas avec des données qu’il a lui-même soft-labellisé, pour éviter qu’il renforce ses biais… on distille ! Par exemple sur le schéma, à l’itération 1, le jeu d’entraînement T fourni au modèle 4, i.e. T14, est constitué de données soft-labellisées par les modèles 1 et 2, en plus des données annotées par l’humain. Puis on prend le deuxième tiers de données à annoter, on en fournit un quart à chaque modèle pour soft-labellisation et on finit la deuxième itération.</p><p>Pour la troisième itération, vous avez compris le principe je pense…   </p><p>À la fin, les millions de commentaires sont plutôt bien soft-labellisés, à la vitesse de la machine et au coût de l’électricité, tout est prêt pour un classifieur sur le schéma d’Ekimetrics et je vous ai expliqué tous les termes entourés sur la figure et présenté toutes les étapes. </p><h2>Avantages, inconvénients, limites et améliorations.</h2><p>Nous avons déjà vu certains des avantages. Internet est une place sur laquelle il y a pléthore d’avis en tout genre : films, restaurants, hôtels, produits de grande consommation, lieux divers… Annoter ces données serait un travail coûteux et sans fin, nous l’avons dit. L’approche iPET permet d’automatiser cette étape, à la vitesse de l’ordinateur et quel que soit le cas d’étude.</p><p>Du point de vue des performances, Ekimetrics a indiqué avoir une précision de 88% avec seulement 50 données labellisées au départ, et même 84% avec 10 données labellisées !! En comparaison, les modèles supervisés peuvent atteindre des précisions de 99%, mais au prix d’un énorme travail de pré-traitement. C’est donc un pas conceptuel de plus dans la réduction de la supervision.</p><p>Toutefois, le domaine d’application se restreint à des données textuelles assez courtes d’une part. Et d’autre part, la charge de travail est déplacée vers une bonne conceptualisation du cas d’étude. Les résultats sont extrêmement dépendants de la formulation des patterns et des choix de verbalizers (i.e. choix du prompting). Ceux-ci impliquent une grande variabilité qui n’est pas maîtrisée. De plus le PLM utilisé - un modèle BERT dans le cas d’Ekimetrics, cache des inconnues sur le corpus qui a servi à son entraînement, son domaine d’applicabilité, ses paramètres. On touche là à une limite dans laquelle l’IA n’est plus tout à fait de l’open science.</p><hr/><h1>Notes de Xavier que je n&#x27;ai pas mises</h1><h2>LIMITES et PISTES D&#x27;AMÉLIORATIONS</h2><p>PLM ou Foundation modèle avec quelles données a-t-il été entraîné ???</p><p>Que donnerait l’utilisation de plusieurs PLM ?</p><p>une amélioration de ces approches est proposé dans le papier <a href="https://arxiv.org/pdf/2103.11955.pdf">https://arxiv.org/pdf/2103.11955.pdf</a>.</p>]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[My first GitHub blog! (strongly inspired by Ekimetrics'...)]]></title>
            <link>https://drkapichu.github.io/blog/welcome</link>
            <guid>welcome</guid>
            <pubDate>Fri, 15 Oct 2021 00:00:00 GMT</pubDate>
            <description><![CDATA[Welcome to the first post! Short text, but sexy... People are eager to know more.]]></description>
            <content:encoded><![CDATA[<h1>And here is the content of my first blog...</h1><h2>Welcome to our technology website!</h2><p>We have been working in the Data Science industry for 15 years and are now the biggest pure player in Europe with 250+ data profiles. We have been benefiting from the open source community for a while, and we want to give back to the community by sharing insights on what we&#x27;ve learned over the years:</p><ul><li><a href="/blog">Blog</a> - read articles on various Data topics: from industrialization on cloud platforms to exotic Deep Learning algorithms</li><li><a href="/opensource">Open source contributions</a> - browse our own open source contributions (Python libraries, code snippets)</li></ul><p>💌 After reading behind the scenes of the Data Science Company, feel free to <a href="mailto:inno@ekimetrics.com">send us a email</a> for any questions or feedbacks! </p><h2>About Ekimetrics</h2><p>Ekimetrics is the first pure player in Data Science in Europe. We operate from Paris, London, New York and Hong Kong with 250+ Data Scientists, Data Engineers, Full Stack Developers, strategy consultants and UX designers. </p><p>We help companies steer their data opportunity, build data capabilities, and deploy actionable solutions, to power up marketing and operational performance, as well as (re)energizing business models. Our primary focus is to deliver immediate business gains, while guaranteeing sustainable data capital for our clients.</p>]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[L’artisanat de la science des données avec datacraft]]></title>
            <link>https://drkapichu.github.io/blog/datacraft-binaire</link>
            <guid>datacraft-binaire</guid>
            <pubDate>Tue, 23 Mar 2021 00:00:00 GMT</pubDate>
            <description><![CDATA[Article publié dans binaire le 23/03/2021]]></description>
            <content:encoded><![CDATA[<p>Cet article a été initialement publié le 23/03/2021 dans <a href="https://www.lemonde.fr/blog/binaire/2021/03/23/lartisanat-de-la-science-des-donnees-avec-datacraft/">binaire</a>, blog créé en janvier 2014 dans le journal <a href="https://www.lemonde.fr/blog/binaire/a-propos/">Le Monde</a> à l’initiative de Serge Abiteboul et de plusieurs collègues de la Société Informatique de France, afin de communiquer sur ce qu’est vraiment l’informatique en tant que science et technique.</p><p>.</p><p>.</p><p>.</p><p><strong>Job : Rendre visible les légendes des images.</strong></p><p>.</p><p>.</p><p>.</p><hr/><h1>L’artisanat de la science des données avec datacraft</h1><p><strong>Image here</strong>
<img src="./img/2021-03-23-binaire/Hiba.png" alt="image" title="**Courteousy of Hiba Kalache, therefore the most profound though is a beating heart (bannière du site de datacraft)**"/>
<strong>il manque une légende pour cette image</strong></p><p><strong>Datacraft</strong>, c’est quoi ce « machin » ? On est à Sorbonne Université <strong>[1]</strong>, dans le Sorbonne Center for Artificial Intelligence, sur le campus de Jussieu, un haut lieu des sciences. Pourtant, ce n’est pas un labo universitaire, même si cela y ressemble. Ça tient du club, un peu du fablab. C’est un espace de cotravail apprenant où on travaille vraiment en commun, plus que dans un espace de cotravail classique. Officiellement, c’est une startup. En fait, ce n’est pas facile à classifier, ce qui est pour moi assez positif dans le monde de la science des données qui se réinvente en permanence.</p><p>J’ai été tenté de dire que c’était un « temple des données » tant les données sont au centre des préoccupations de tous et toutes dans ce lieu. Mais non, les données ne sont pas adorées ici, elles sont questionnées, challengées. On vous parle ici de leur mise au service des entreprises et de la société, de « responsabilité sociale des données ».</p><p>En fait, la vraie valeur, il faut la chercher dans le nom de l’entreprise, datacraft, en français « l’artisanat de la science des données » (traduction personnelle). C’est tellement plus joli qu’en anglais, même si c’est certainement moins vendeur. Avec datacraft, nous sommes bien dans l’artisanat, dans un savoir-faire spécifique, hors contexte industriel de masse. Nous sommes pile poil dans le compagnonnage en sciences des données, dans l’idée de se former en faisant, en échangeant, en bénéficiant de conseils d’experts.</p><p>Je pense qu’un tel compagnonnage est particulièrement bien adapté à la science des données. En 2014, dans un rapport pour le gouvernement <strong>[2]</strong>, nous parlions de la nécessité de booster les formations aux sciences des données, en insistant sur le caractère indispensable de projets « les yeux dans les yeux, de données en vraie grandeur ». Depuis, de telles formations ont vu le jour et les entreprises ont souvent maintenant leurs data scientists. Mais ceux-ci souffrent d’être isolés, de ne pas pouvoir partager leurs questionnements, leurs expériences. L’image du geek qui bosse seul dans son coin est à des kilomètres de la réalité de l’informatique – on travaille le plus souvent en équipe – et tout particulièrement dans la science des données. Un beau projet en science des données met typiquement en jeu des compétences variées que l’on trouve rarement chez une personne unique : gestion de données, big data, machine learning, compétence métier, etc.</p><p><strong>Image here</strong>
<img src="./img/2021-03-23-binaire/Atelier.png" alt="image" title="**©datacraft, atelier computer vision au service de l’imagerie médicale**"/>
<strong>il manque une légende pour cette image</strong></p><p>Les data scientists des entreprises adhérentes à datacraft peuvent venir travailler dans un espace de cotravail où ils rencontreront des data scientists, leurs homologues d’autres entreprises et des experts résidence. Il ne s’agit pas juste de partager de beaux bureaux et du café.  Ils peuvent par exemple dans des ateliers pratiques échanger des idées, apprendre, et partager. Et ce contexte permet aux idées d’infuser entre des domaines différents.</p><p>Par exemple, datacraft a organisé un atelier avec l’INSEP (l‘Institut national du sport, de l’expertise et de la performance) autour de l’utilisation de données dans le sport de haut niveau. Il s’agissait d’arriver à construire la meilleure équipe selon le contexte, les adversaires, la météo, etc. Il était difficile de prévoir l’intérêt des ingés de Vinci Autoroutes sur ce sujet, pourtant, ils ont apporté une expertise précieuse.</p><p><strong>Image here</strong>
<img src="./img/2021-03-23-binaire/INSEP.png" alt="image" title="**Image: https://pixabay.com/users/clker-free-vector-images-3736/**"/>
<strong>il manque une légende pour cette image</strong></p><p>Pas de bol, datacraft s’est lancée en février 2020, pas le meilleur moment pour un concept basé sur un lieu de rencontre physique. Les membres ont initié des projets autour de la santé et de l’éducation, pour aider la société dans un temps de crise sanitaire grave. Je me serais aussi attendu à ce qu’ils découvrent les avantages considérables du travail à distance, d’une certaine inutilité de la rencontre physique. Pas du tout, Isabelle Hilali, fondatrice et pédégère de datacraft, explique : « Pour moi, la dimension physique est essentielle, et j’aimerais revenir dès que possible au présentiel car il est important de garder du lien. » Et quand j’insiste sur les avantages du distanciel, elle précise : « Il faut aussi le plaisir du travail. Il y a moins de plaisir à collaborer à distance. »</p><p>Quand on met des gens brillants ensemble, les initiatives fleurissent. Des membres se regroupent pour former des consortiums et répondre à des appels à projets ambitieux auxquels ils n’auraient pas les moyens de répondre individuellement. Ils mettent en place des formations, des espaces d’échanges dans des domaines spécifiques comme les ressources humaines ou les aspects légaux des applications de la science des données.</p><p>J’ai parlé de datacraft à des collègues chiliens. Leur réaction : un tel club serait encore plus indispensable au Chili où les data scientists des entreprises sont encore plus isolés qu’en France. Je pense que c’est vrai pour de nombreux pays, datacraft devrait donc s’exporter ? J’ai posé la question : ils ouvrent une base au Maroc en 2022. À quand le Chili ?</p><p>Postscriptum : Quand je m’enthousiasme pour une startup dans binaire, il se trouve parfois un de nos très chers lecteurs pour questionner mon objectivité, m’accuser d’avoir des amis dans la startup, d’y avoir investi, voire de me faire payer pour la pub. Et bien non rien de tout cela. J’ai trouvé que c’était une idée géniale et j’ai voulu la raconter.</p><p><a href="https://fr.wikipedia.org/wiki/Serge_Abiteboul">Serge Abiteboul</a>, Inria et ENS, Paris</p><hr/><p><strong>[1]</strong> Sorbonne Université est une université française située à Paris. Elle a été créée le 1er janvier 2018 par regroupement des universités Paris-Sorbonne (Paris-IV) et Pierre-et-Marie-Curie (Paris-VI), elles-mêmes créées en 1970 et héritières de l’université de Paris fondée en 1896.</p><p><strong>[2]</strong> Serge Abiteboul, François Bancilhon, François Bourdoncle, Stephan Clemencon, Colin De La Higuera, et al. L’émergence d’une nouvelle filière de formation : data scientists », 2014 <a href="https://hal.inria.fr/hal-01092062">https://hal.inria.fr/hal-01092062</a></p>]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[Classification des mains de scribes assistée par l’intelligence artificielle]]></title>
            <link>https://drkapichu.github.io/blog/egyptologie</link>
            <guid>egyptologie</guid>
            <pubDate>Thu, 04 Mar 2021 00:00:00 GMT</pubDate>
            <description><![CDATA[Article publié dans Archeologia Magazine le 04/03/2021]]></description>
            <content:encoded><![CDATA[<p>Cet article a été initialement publié le 04/03/2021 dans <a href="https://www.archeologia-magazine.com/numero-596/egypte-dernieres-decouvertes/egypte-dernieres-decouvertes.53184.php#article_53184"> Archeologia Magazine</a>, magazine payant d&#x27;archéologie.</p><p>.</p><p>.</p><p>.</p><p><strong>Cet article est payant. TOutefois je l&#x27;ai sur mon ordi, dans les documents de l&#x27;égypto, mais il est particulièrement long et structuré d&#x27;une manière que je ne pourrais pas reproduire en markdown.</strong></p><p><strong>Que faire ?</strong>
.</p><p>.</p><p>.</p><hr/><h1>Un titre</h1>]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[datacraft - un club dédié à la data science et l’Intelligence Artificielle]]></title>
            <link>https://drkapichu.github.io/blog/datacraft</link>
            <guid>datacraft</guid>
            <pubDate>Mon, 15 Feb 2021 00:00:00 GMT</pubDate>
            <description><![CDATA[Article publié dans Visionary le 15/02/2021]]></description>
            <content:encoded><![CDATA[<p>Cet article a été initialement publié le 15/02/2021 dans <a href="https://visionarymarketing.com/fr/2021/02/datacraft-data-science-et-ia/?mc_cid=a430616615&amp;mc_eid=0bd4a33d6d">Visionary</a>, site d&#x27;infos des marketeurs et innovateurs visionnaires depuis 1996.</p><p>.</p><p>.</p><p>.</p><p><strong>Job : Voir si possible d&#x27;inclure l&#x27;audio de l&#x27;interview d&#x27;Isabelle.</strong></p><p><strong>Job : Travailler la présentation pour montrer que c&#x27;est une vidéo.</strong></p><p><strong>Job : Rendre visible les légendes des images.</strong></p><p><strong>Job : Changer le style des citations.</strong></p><p>.</p><p>.</p><p>.</p><hr/><h1>Datacraft : un club dédié à la data science et l’Intelligence Artificielle</h1><p>Un club Data Science et IA ? Là où beaucoup veulent absolument qu’on remplace les humains par des robots, les experts de l’IA démontrent la supériorité des échanges humains. Car il y avait un besoin d’échange dans la communauté de la data science et <a href="https://www.linkedin.com/in/isabelle-hilali-82b5111/">Isabelle Hilali</a>, CEO et fondatrice de Datacraft, que <a href="https://visionarymarketing.com/fr/2016/09/big-data-sante-combinaison-necessaire/">nous avions déjà interviewée</a> ici il y a quelques années, l’avait pressenti. Elle n’a pas hésité à lancer son club data science en plein milieu de la crise du Covid et a démontré, même en ces temps difficiles que tout est possible. Elle a démontré également que la nécessité de se parler, y compris pour les experts de l’IA et de la data science, est plus forte que jamais. Retour sur la création d’un club hors du commun, où se dessine collaborativement le futur de vos logiciels. </p><h2>Datacraft : un club data science et IA installé au cœur de La Sorbonne</h2><p><img src="./img/2021-02-15-datacraft/datacraft-scai.png" alt="image" title="J’ai rencontré Isabelle Hilali dans ses locaux du SCAI (Sorbonne Center for Artificial Intelligence) qui héberge Datacraft, le club de la data science et de l’IA qu’elle a créé"/>
<strong>il manque une légende pour cette image</strong></p><blockquote><p>&quot;J’ai observé que l’univers de la data science et des data scientists est un domaine sur lequel il faut apprendre tout le temps et où tout va extrêmement vite.&quot;
Isabelle Hilali – Datacraft</p></blockquote><p>« En data science, il est vraiment compliqué d’être à la pointe en termes de compétences. C’est un univers où l’on a besoin de partager. On a toujours l’image du geek qui est seul derrière son micro, mais en fait, si on veut être bon, il faut croiser les données et être imaginatif » explique Isabelle.</p><p>C’est un univers sur lequel il y a beaucoup de liberté puisque ce sont des métiers très demandés alors que trop peu de bonnes compétences sont disponibles. Les data scientists peuvent donc quelque peu « imposer » la façon dont ils ont envie de travailler. Et ils ont envie de travailler de manière flexible.</p><blockquote><p>&quot;L’idée, c’était d’avoir un lieu qui donne envie de collaborer&quot;</p></blockquote><p>Le Centre d’intelligence artificielle de la Sorbonne a été imaginé pour permettre de se retrouver pour collaborer. C’est un lieu ouvert. Et c’est là que Datacraft s’est implanté, entre la tour de Jussieu et le jardin des plantes.</p><iframe width="85%" height="500px" src="https://www.youtube.com/embed/0xtPrTo-13o" alt="Présentation de datacraft par Isabelle" title="YouTube video player" frameBorder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe><h2>Un portrait robot du data scientist ? Impossible tant ce mot recouvre des réalités différentes</h2><p>J’aimerais bien faire un portrait robot de la <a href="https://visionarymarketing.com/fr/2015/07/data-scientist/">data scientist</a>, mais il n’y en a pas beaucoup pour l’instant … Alors j’ai commencé par le data scientist au sens large.</p><blockquote><p>&quot;Il n’y a pas de portrait robot du data scientist. Ce mot est utilisé un peu à tort et à travers. Il recouvre différentes réalités&quot;</p></blockquote><p>Il y a également le data ingénieur, le data scientist, le data analyst. Il y a besoin de préparer les données, de développer des modèles, d’intégrer aussi tout cela dans le système d’information.</p><p>Certains ont une formation assez classique, une grande école d’ingénieurs ou une grande école de math et d’informatique. Mais d’autres ont fait de la musique et ensuite se sont formés à la datascience.</p><p><img src="./img/2021-02-15-datacraft/datacraft-scai.png" alt="image" title="Même masqués, les ateliers datacraft de data science sont un moment privilégié d’échange et de travail"/>
<strong>il manque une légende pour cette image</strong></p><p>Le bon data scientist, qui va être performant dans une organisation, doit être curieux. Il doit être ouvert à l’organisation dans laquelle il est, pour comprendre la situation et éviter de construire des modèles abstraits qui ne serviront à rien. Il doit comprendre les problématiques en allant chercher des données, en faisant de l’apprentissage machine, en développant des modèles, en s’interrogeant sur la meilleure façon d’aider à la connaissance, à la prise de décision.</p><blockquote><p>&quot;Pour moi, le bon data scientist est quelqu’un d’ouvert et de collaboratif, et qui a des compétences en mathématiques et en informatique, ou au moins la capacité à travailler sur ces sujets&quot;</p></blockquote><h2>La nécessité d’apprendre dans le domaine de la data science</h2><p>Le besoin principal sur lequel j’avais envie de travailler, était la nécessité d’apprendre en permanence.</p><p>Il existe bien des formations en ligne, des formations physiques, des livres, des communautés pour faire de la recherche. Mais il n’existait pas de lieu physique où partager les choses.</p><p><strong>J’ai été assez inspirée par le modèle du compagnonnage</strong>, c’est une chouette façon d’apprendre, avec les autres, en le revisitant un peu, car dans notre modèle, chacun apprend aux autres, il n’y a pas de maître ni d’élève. Chacun est maître sur un bout de sujet.</p><p>Je me suis dit qu’il faudrait qu’il y ait des lieux qui permettent aux gens un échange de bonnes pratiques et qui soient pensés pour ça. Et en même temps qui développent la collaboration et la réflexion sur ce qu’on fait, quelles limites on veut donner quand on développe de l’intelligence artificielle.</p><blockquote><p>&quot;Notre volonté avec Datacraft était de créer ce réseau de lieux pour se retrouver entre experts pour un échange de bonnes pratiques&quot;</p></blockquote><h2>Le lancement de Datacraft, le club data science et IA</h2><p>J’ai lancé DataCraft en janvier 2020, avec le groupe Accor et l’Insep, les deux premiers membres qui m’ont fait confiance, et dans de supers locaux dans le Marais.</p><p>Tout cela a pris forme début février avec l’ouverture des locaux, avec également notre système de résidence où l’on accueille à la fois des chercheurs, et des freelances qui font partie de la communauté, qui ne paient pas d’adhésion, mais qui donnent du temps à la communauté.</p><p>Et puis tout a fermé un mois plus tard avec le confinement …</p><p>Le concept étant de mettre les gens ensemble et d’avoir cette complémentarité avec ce qui existe en digital, j’ai pensé qu’il allait falloir fermer.</p><p>Et puis finalement, on avait encore davantage besoin de cet échange de bonnes pratiques, de cette solidarité entre experts et de cette créativité.</p><p>La communauté a énormément grossi. Nous sommes passés de 80 a plus de 500 en fin de confinement, en fédérant des gens qui avaient envie de s’entraider.</p><h2>Un club data science : comment ça marche ?</h2><p>Par exemple, un membre va communiquer sur le développement d’une application en Python, alors qu’il a l’habitude de faire sur <a href="https://help.adobe.com/en_US/air/build/index.html">Adobe Air</a>, et poser la question si d’autres membres ont déjà fait cela pour un type d’applications, pour un tableau de bord par exemple.</p><p>La demande est lancée dans la communauté, des membres vont répondre et au lieu que ce soit deux personnes qui se parlent, on en profite pour organiser un atelier, virtuellement pendant le Covid, où les gens vont partager leurs bonnes pratiques. Souvent, à la fin de l’atelier, un atelier suivant se dessine de par les échanges qui ont eu lieu sur par exemple une bibliothèque que les membres n’avaient jamais pensé à utiliser comme ça.</p><p>Puis, il y a eu le premier déconfinement et nous avons recommencé à faire des ateliers en physique.</p><p>Nous avons organisé un atelier, par exemple, sur les données du sport de haut niveau, avec des problématiques telles qu’aider un entraîneur à optimiser son équipe, à choisir l’équipe qui sera la plus performante en fonction des adversaires, en fonction de données, de météo ou de tout cet environnement.</p><p>C’est un prétexte. Sur un projet comme ça, des membres vont venir pendant deux jours travailler ensemble, des gens de l’Insep, de Vinci Autoroutes, d’un labo pharmaceutique, d’une petite startup qui va travailler sur des données des réseaux sociaux, par exemple. Et tous ces gens vont travailler ensemble pendant deux jours.</p><p>Contrairement à un hackathon, notre objectif n’est pas de faire un prototype au bout de deux jours qui souvent, en outre, n’est pas très bon.</p><blockquote><p>&quot;Notre seule volonté est qu’à la fin des deux jours ou de la demi-journée, les participants repartent en se disant  » C’est génial, j’ai appris telle chose »&quot;</p></blockquote><p>C’est ça notre objectif, un échange de bonnes pratiques, où même les « super experts » apprennent quelque chose.</p><p>Cela va bien au delà bien sûr. De nombreux partenariats se nouent, qu’on n’aurait jamais imaginé. Un partenariat entre Vinci Autoroutes et le sport de haut niveau par exemple.</p><p>Ou encore une startup qui travaille sur les données des réseaux sociaux en santé, qui va découvrir une expertise complémentaire chez un membre de Datacraft, et envisager de monter un gros projet européen sur les fakenews médicales.</p><p>Ou encore Danone, par exemple, qui est en train de rédiger sa <a href="https://visionarymarketing.com/fr/glossaire/marketing-ethique/">charte</a> sur l’utilisation responsable des données, qui la réalise avec d’autres membres qui l’ont déjà fait pour l’écrire ensemble.</p><h2>L’avenir pour Datacraft, le club de la data science</h2><p>L’idée était d’avoir un lieu qui donne envie de collaborer et de se poser des questions sur la façon dont on travaille la data, quelle responsabilité on a envers la société.</p><p>L’idée était aussi d’avoir dans Paris un lieu avec un jardin, des plantes, qui favorise cette collaboration et cette réflexion.</p><p>Nous sommes au Centre d’intelligence artificielle de la Sorbonne, et cela fait énormément de sens. Le Centre d’intelligence artificielle de la Sorbonne a été imaginé pour permettre à tout l’écosystème de Sorbonne universités, le Museum d’histoire naturelle, l’IRCAM en musique, la fac de médecine, de se retrouver pour collaborer.</p><p>C’est un lieu ouvert où les entreprises sont les bienvenues. Etre hébergés ici, à côté du Jardin des Plantes, est complètement en phase avec nos valeurs.</p><p><strong>Dans le futur, il y aura d’autres bases datacraft</strong> qui seront toutes imaginées autour de ce concept de collaboration et de responsabilité.</p><h2>Le Covid : crise ou opportunité ?</h2><p>Cela a été aussi une source de créativité pour nous, Cela nous a permis de faire des choses à distance, et d’avoir, par exemple, des personnes en Ouganda qui nous ont demandé de participer à un atelier. Nous n’aurions pas pu faire ce genre de choses aussi rapidement.</p><p>Et puis, ça nous a montré ce besoin de solidarité et d’échange de bonnes pratiques.</p><blockquote><p>&quot;Même si on espère bien sûr que ça durera pas trop longtemps, cette période a finalement encore renforcé nos valeurs&quot;</p></blockquote>]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[Téléconsultation - une porte d’entrée dans le parcours de soins ?]]></title>
            <link>https://drkapichu.github.io/blog/Teleconsultation</link>
            <guid>Teleconsultation</guid>
            <pubDate>Fri, 27 Nov 2020 00:00:00 GMT</pubDate>
            <description><![CDATA[Article publié dans Pharmaceutiques le 27/11/2020]]></description>
            <content:encoded><![CDATA[<p>Cet article a été initialement publié le 27/11/2020 dans <a href="https://pharmaceutiques.com/actualites/nouvelles-technologies/teleconsultation-une-porte-dentree-dans-le-parcours-de-soins/">Pharmaceutiques</a> journal spécialisé dans les secteurs de la santé et du médicament.</p><hr/><h1>Téléconsultation : une porte d’entrée dans le parcours de soins ?</h1><h2>Une étude menée par la plateforme de télémédecine Qare, en partenariat avec datacraft et Ekimetrics, analyse avec précision 300 000 téléconsultations réalisées en janvier 2019 et juillet 2020.</h2><p>Quel est le profil des utilisateurs de la téléconsultation ? Et qui a profité en priorité de l’assouplissement du cadre règlementaire décidé en mars dernier en phase d’entrée dans la pandémie de Covid19 ? Au moment où les syndicats de professionnels de santé discutent, dans le cadre conventionnel, des nouvelles modalités de la télémédecine, il apparait essentiel de bien connaitre la structure de ” consommation” de cette nouvelle forme de recours aux soins. C’est dans ce but que la plateforme Qare, l’un des principaux leaders de la téléconsultation, a mené une enquête détaillée, auprès de 2050 praticiens, 180 150 patients, et sur la base de 300 000 téléconsultations. « Notre enquête porte sur une période large, de janvier 2019 à juillet 2020, précise le Dr Julie Salomon, directrice médicale adjointe de Qare. Il faut également tenir compte du fait qu’il ne nous a pas été possible de distinguer les profils de consommation avant et après l’arrivée de la pandémie. » En raison de l’explosion du nombre de téléconsultations à partir de mars, par rapport à la période précédente, la comparaison statistique n’aurait pas été pertinente. Par ailleurs, les données proviennent des téléconsultations opérées par Qare : or, l’entreprise a fait son entrée sur le marché dès janvier 2017, par le biais d’une convention avec l’ARS des Français de l’étranger. « Nous avons initié l’outil avec les Français installés hors de France, avant de pouvoir développer ce qui est notre coeur de métier, l’offre de soin pour les français du territoire national, ajoute Julie Salomon. Cet engagement, antérieur au cadre règlementaire posé en janvier 2019, explique la diversité de notre panel d’utilisateurs.» </p><h2>Des utilisateurs jeunes, un besoin aigu de santé</h2><p>Ces réserves étant posées, l’étude livre des résultats inédits et particulièrement intéressants. Pour la réaliser, Qare s’est appuyé sur l’expertise de deux partenaires : datacraft, une startup avec un modèle de Club qui permet un échange de bonnes pratiques entre experts de la donnée, et le leader européen en data science Ekimetrics. « Le premier enseignement, c’est que la téléconsultation est une solution principalement utilisée par une population jeune et plutôt urbaine, note Soline Aubry, lead du projet pour Ekimetrics. Les patients ont en moyenne 35 ans, contre 41 ans pour l’ensemble de la population française. Et 60% vivent dans l’une des dix plus grandes zones urbaines. » Le mode de consommation est également révélateur : le pic de téléconsultation se situe plutôt tôt, avant 10 heures du matin, et plutôt en début de semaine. « Cela traduit sans doute un besoin de prise en charge rapide, dès l’ouverture des cabinets, analyse Julie Salomon. Le phénomène était moins marqué durant la phase de confinement. » Quels médecins sont consultés en priorité ? D’abord des médecins généralistes, pour 63% des consultations. Les 37% de consultation chez les spécialistes s’effectuent en priorité les dermatologues, les pédiatres et les psychiatres, trois spécialités en forte tension démographique.</p><h2>40% de fidélisation au médecin téléconsulté</h2><p>Utilisée majoritairement pour des affections dites ”courantes” (cystite, rhume, gastro-entérite, état grippal…), la téléconsultation (chez Qare) est un outil, selon les auteurs de l’étude, pour offrir une réponse en urgence face à un besoin de santé aigu. Et il permet, « dans 99% des cas », d’éviter un déplacement inutile chez le médecin. « C’est une donnée importante, car elle laisse entendre que la téléconsultation pourrait permettre de désengorger les cabinets et de faciliter la prise en charge des soins non programmés », estime Julie Salomon. D’autres chiffres révélés par Ekimetrics montrent par ailleurs que si 86% des patients et des médecins ne se connaissaient pas au moment du premier rendez-vous, 40% des patients ont pris le second rendez-vous avec le même médecin. « La téléconsultation peut donc être l’occasion pour les patients d’entrer dans le parcours de soins » ajoute Isabelle Hilali, fondatrice et dirigeante de datacraft.</p><h2>L’enjeu des soins chroniques</h2><p>Première étape d’une étude au long cours, cette enquête sera prolongée, dans les mois à venir, par de nouveaux questionnements. Qui consulte quelles spécialités ? Comment se profilent les parcours de téléconsultation en fonction des typologies de territoires ? L’usage de la téléconsultation décolle-t-il dans les zones de faible densité géographique ? Et les seniors et les malades chroniques s’y engagent-ils ? Enfin, comment la pandémie modifie-t-elle les modalités de recours à la consultation à distance ? Les enjeux d’avenir de la télémédecine se profilent derrière ces questions : pour s’imposer définitivement dans les usages des patients et les pratiques des médecins, elle devra nécessairement contribuer à la fluidité des parcours de soins pour les malades chroniques.</p>]]></content:encoded>
        </item>
    </channel>
</rss>