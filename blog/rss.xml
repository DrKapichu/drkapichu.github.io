<?xml version="1.0" encoding="utf-8"?>
<rss version="2.0" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:content="http://purl.org/rss/1.0/modules/content/">
    <channel>
        <title>datacraft blog Blog</title>
        <link>https://drkapichu.github.io/blog</link>
        <description>datacraft blog Blog</description>
        <lastBuildDate>Fri, 04 Feb 2022 00:00:00 GMT</lastBuildDate>
        <docs>https://validator.w3.org/feed/docs/rss2.html</docs>
        <generator>https://github.com/jpmonette/feed</generator>
        <item>
            <title><![CDATA[Few Shot Learning - application de la mÃ©thode iPET]]></title>
            <link>https://drkapichu.github.io/blog/draft</link>
            <guid>draft</guid>
            <pubDate>Fri, 04 Feb 2022 00:00:00 GMT</pubDate>
            <description><![CDATA[Draft of the first blog]]></description>
            <content:encoded><![CDATA[<p>(<a href="https://numenta.com/blog/2019/08/30/case-for-sparsity-in-neural-networks-part-1-pruning">source</a> de l&#x27;image de prÃ©sentaion)</p><h2>Quâ€™est ce que le Few Shot Learning (FSL) ? - titre alternatif : Sujet du jour : le Few Shot Learning (FSL)</h2><p>Il est bien connu que la puissance des mÃ©thodes de Machine Learning supervisÃ©es, et plus particuliÃ¨rement de Deep Learning avec les rÃ©seaux de neurones, depuis le dÃ©but des annÃ©es 2000, a reposÃ© sur la constitution de <strong>grands jeux de donnÃ©es labellisÃ©s</strong>. Deux Ã©lÃ©ments sont importants ici : â€˜grandsâ€™ et â€˜labellisÃ©sâ€™.</p><p>Pour le premier point, Ã§a reprÃ©sente par exemple des milliers, voire des millions dâ€™images pour la Computer Vision et des millions dâ€™ensembles de phrases pour le NLP. Concernant le second point, il signifie quâ€™au cours de son apprentissage, lâ€™ordinateur compare son Ã©valuation des donnÃ©es avec le label quâ€™un intervenant humain a associÃ© Ã  chaque donnÃ©e.</p><p>Dans le cas du <strong>Few Shot Learning (FSL)</strong>, les chercheurs veulent crÃ©er des mÃ©thodes capables dâ€™apprendre avec peu de donnÃ©es, i.e. des dizaines ou des centaines, ce qui reprÃ©sente un gain de temps et dâ€™Ã©nergie, tout en conservant des performances Ã©quivalentes aux modÃ¨les traditionnels bien sÃ»r. Câ€™est pourquoi en franÃ§ais on parle dâ€™<strong>apprentissage frugal</strong>. Toutefois, en pratique les mÃ©thodes de FSL prennent un modÃ¨le traditionnel, prÃ©-entraÃ®nÃ© sur un grand nombre de donnÃ©es, et elles le spÃ©cialisent sur le cas dâ€™usage via une courte phase dâ€™apprentissage sur le petit jeu de donnÃ©es Ã  disposition ; câ€™est du fine-tuning. Mais en plus, le Few Shot câ€™est une mÃ©thode qui va au-delÃ  des mÃ©thodes traditionnelles, elle permet de faire du semi-supervisÃ©, câ€™est ce quâ€™on va voir avec le cas dâ€™usage.</p><h2>Le cas dâ€™usage - titre alternatif : Câ€™est quoi le problÃ¨me ?!</h2><p>Ekimetrics sâ€™est intÃ©ressÃ© Ã  lâ€™apprentissage frugal pour exploiter les Ã©normes jeux de donnÃ©es des petits commentaires quotidiens sur internet, avec une problÃ©matique de gain de tempsâ€¦ De la frugalitÃ© avec des Ã©normes jeux de donnÃ©es ? On vous explique !</p><p>Mieux que le seul nombre dâ€™Ã©toiles dâ€™un restaurant ou dâ€™un hÃ´tel, il sâ€™agit de prendre en compte les avis dans les tweets, les posts, les brÃ¨vesâ€¦ qui sont par essence des donnÃ©es non labellisÃ©es et de les exploiter. Lâ€™annotation humaine de ces avis est inenvisageable. Ã‡a coÃ»terait trop cher, Ã§a prendrait trop de temps, et il faudrait recommencer tous les jours pour suivre lâ€™Ã©volution du sentiment. En l&#x27;occurrence, pour la recherche dâ€™Ekimetrics, le sujet dâ€™Ã©tude porte sur des commentaires de restaurants.</p><p>Mais si la machine Ã©tait capable dâ€™Ã©valuer les commentaires, Ã  2 Gigahertz, tout de suite le problÃ¨me serait rÃ©glÃ©. Câ€™est lÃ  que le Few Shot, en utilisant la mÃ©thode PET, peut devenir utile.</p><p>Dans la suite, nous vous prÃ©sentons la mÃ©thode PET, comment lâ€™utiliser dans le cadre du FSL et enfin, comment Ekimetrics lâ€™utilise sur les avis des consommateurs.</p><h2>PET quâ€™est ce que câ€™est ?</h2><p><strong>PET</strong> est lâ€™acronyme de â€˜<strong>Pattern Exploiting Training</strong>â€™. La mÃ©thode repose sur un ensemble fixe et prÃ©dÃ©fini de <strong>patterns</strong> et de <strong>verbalizers</strong> et un <strong>Pre-trained Language Model</strong> a.k.a. <strong>PLM</strong>. Les patterns sont les phrases Ã  trou (â€œIt wasâ€¦â€, â€œJustâ€¦!â€, â€œAll in all, it wasâ€¦â€, â€œIn summary, the restaurant isâ€¦â€) et les verbalizers sont les mots qui peuvent complÃ©ter ces phrases et auxquels sont associÃ©es des notes chiffrÃ©es. On commence Ã  retrouver les nombres que lâ€™ordinateur aime tant !</p><p>ConcrÃ¨tement, reprenons notre exemple des Ã©valuations des restaurants, la mÃ©thode consiste Ã  :</p><ul><li>prendre un commentaire,</li><li>y associer alÃ©atoirement un pattern,</li><li>soumettre le tout au PLM qui va le complÃ©ter en choisissant un verbalizer.</li></ul><p><img src="./img/2022-02-04-MindshakeTime/PET.png"/></p><p>Par exemple (voir Fig. 1), avec le commentaire â€œBest pizza ever!â€, on construit la phrase Ã  trou : â€œBest pizza ever! It was â€¦ .â€ que le PLM va complÃ©ter avec â€˜greatâ€™ avec une confiance de 0.8, sachant que ce mot est notÃ© +1.</p><h2>FSL + PET : premiÃ¨re application aux avis internet</h2><p>Revenons Ã  la masse brute des avis des consommateurs sur internet. <strong>PET est la mÃ©thode</strong> pour associer une note Ã  un commentaire, le <strong>FSL est le moyen</strong> de traiter automatiquement tout le jeu de donnÃ©es, et le travail de lâ€™algorithme se fait en deux Ã©tapes.</p><p>Dans un premier temps, on labellise un petit nombre de commentaires, une centaine par exemple, ce qui signifie quâ€™on associe une paire pattern plus verbalizer Ã  ces commentaires, et on finetune le PLM avec cette centaine. Puis, une fois le PLM spÃ©cialisÃ©, on le laisse labelliser tout le reste du jeu de donnÃ©es, automatiquement. Ã‡a en fait une mÃ©thode semi-supervisÃ©e dâ€™analyse de sentiment des commentaires.</p><p>Cependant, cette application basique prÃ©sente des limites. Dâ€™une part, le verbalizer donnÃ© par le PLM peut ne pas Ãªtre le plus adaptÃ© au commentaire et, dâ€™autre part, câ€™est trÃ¨s ambitieux de spÃ©cialiser le PLM une fois sur une centaine dâ€™exemples pour ensuite en traiter des dizaines de milliers ou plus. Câ€™est pourquoi les chercheurs ont dÃ©veloppÃ© une mÃ©thode de distillation qui augmente la robustesse de PET, câ€™est la mÃ©thode <strong>iPET : iterative PET</strong>.</p><h2>i(terative)PET : une mÃ©thode de distillation astucieuse</h2><p>Une image peut valoir mille motsâ€¦</p><p><img src="./img/2022-02-04-MindshakeTime/iPET.png"/></p><p>â€¦ Mais quelques mots seront quand mÃªme nÃ©cessaires pour expliquer cette image !</p><p>Tout dâ€™abord, le schÃ©ma de gauche sur la figure prÃ©sente lâ€™adaptation de PET qui permet dâ€™obtenir le label le plus adaptÃ© au commentaireâ€¦ en moyenne. En effet, il sâ€™agit â€˜simplementâ€™ de <strong>faire travailler des mÃ©thodes PET indÃ©pendantes en parallÃ¨le</strong> (trois sur le schÃ©ma). Les trois cellules ont le mÃªme PLM au dÃ©part, et elles travaillent sur les mÃªmes commentaires, mais avec des patterns diffÃ©rents. Dans la phase dâ€™entraÃ®nement sur les donnÃ©es labellisÃ©es, les PLMs se spÃ©cialisent diffÃ©remment. Puis, durant la phase de travail, pour un mÃªme commentaire ils produisent des <strong>paires pattern-verbalizers</strong> (appelÃ©es <strong>PVPs</strong> sur le schÃ©ma) indÃ©pendamment les uns des autres ; possiblement les mÃªmes, mais pas avec les mÃªmes probas. Enfin, <strong>en sortie</strong> ces (trois) labels sont utilisÃ©s pour calculer <strong>un soft-label</strong>, i.e. un <strong>label moyen</strong>.</p><p>Ensuite, sur la droite est prÃ©sentÃ© le caractÃ¨re itÃ©ratif de la mÃ©thode iPET. Elle consiste Ã  diviser le jeu labellisÃ©s sur plusieurs itÃ©rations (indiquÃ©es par les exposants allant de 0 Ã  k) et Ã  diviser encore Ã  chaque itÃ©ration entre plusieurs mÃ©thodes parallÃ¨les (indiquÃ©es par les indices allant de 0 Ã  4). Mais attention, chacun des quatre modÃ¨les ici fait du soft-labelling comme prÃ©sentÃ© Ã  gauche de la figure, câ€™est-Ã -dire quâ€™ils contiennent plusieurs mÃ©thodes en parallÃ¨le.</p><p>Donc, si lâ€™on suppose que lâ€™on part pour trois itÃ©rations, lâ€™information labellisÃ©e est distillÃ©e de la maniÃ¨re suivante. Ã€ lâ€™itÃ©ration 0 sur le schÃ©ma, on prend un tiers des donnÃ©es labellisÃ©es, et on fournit un quart de ces donnÃ©es Ã  chaque modÃ¨le pour le finetuner, avant de prendre un tiers des donnÃ©es Ã  labelliser et dâ€™en fournir un quart Ã  chaque modÃ¨le pour soft-labellisation. Ce qui constitue la fin de la premiÃ¨re itÃ©ration.</p><p>Ã€ la deuxiÃ¨me itÃ©ration - itÃ©ration 1 sur le schÃ©ma, on commence Ã  nouveau par un phase de fine-tuning, mais avec un jeu de donnÃ©es labellisÃ©es constituÃ© pour partie des donnÃ©es annotÃ©es par un Ãªtre humain (le deuxiÃ¨me tiers), et pour partie de donnÃ©es soft-labellisÃ©es. Toutefois, on fait attention Ã  ce quâ€™un modÃ¨le ne sâ€™entraÃ®ne pas avec des donnÃ©es quâ€™il a lui-mÃªme soft-labellisÃ©, pour Ã©viter quâ€™il renforce ses biaisâ€¦ on distille ! Par exemple sur le schÃ©ma, Ã  lâ€™itÃ©ration 1, le jeu dâ€™entraÃ®nement T fourni au modÃ¨le 4, i.e. T14, est constituÃ© de donnÃ©es soft-labellisÃ©es par les modÃ¨les 1 et 2, en plus des donnÃ©es annotÃ©es par lâ€™humain. Puis on prend le deuxiÃ¨me tiers de donnÃ©es Ã  annoter, on en fournit un quart Ã  chaque modÃ¨le pour soft-labellisation et on finit la deuxiÃ¨me itÃ©ration.</p><p>Pour la troisiÃ¨me itÃ©ration, vous avez compris le principe je penseâ€¦   </p><p>Ã€ la fin, les millions de commentaires sont plutÃ´t bien soft-labellisÃ©s, Ã  la vitesse de la machine et au coÃ»t de lâ€™Ã©lectricitÃ©, tout est prÃªt pour un classifieur sur le schÃ©ma dâ€™Ekimetrics et je vous ai expliquÃ© tous les termes entourÃ©s sur la figure et prÃ©sentÃ© toutes les Ã©tapes. </p><h2>Avantages, inconvÃ©nients, limites et amÃ©liorations.</h2><p>Nous avons dÃ©jÃ  vu certains des avantages. Internet est une place sur laquelle il y a plÃ©thore dâ€™avis en tout genre : films, restaurants, hÃ´tels, produits de grande consommation, lieux diversâ€¦ Annoter ces donnÃ©es serait un travail coÃ»teux et sans fin, nous lâ€™avons dit. Lâ€™approche iPET permet dâ€™automatiser cette Ã©tape, Ã  la vitesse de lâ€™ordinateur et quel que soit le cas dâ€™Ã©tude.</p><p>Du point de vue des performances, Ekimetrics a indiquÃ© avoir une prÃ©cision de 88% avec seulement 50 donnÃ©es labellisÃ©es au dÃ©part, et mÃªme 84% avec 10 donnÃ©es labellisÃ©es !! En comparaison, les modÃ¨les supervisÃ©s peuvent atteindre des prÃ©cisions de 99%, mais au prix dâ€™un Ã©norme travail de prÃ©-traitement. Câ€™est donc un pas conceptuel de plus dans la rÃ©duction de la supervision.</p><p>Toutefois, le domaine dâ€™application se restreint Ã  des donnÃ©es textuelles assez courtes dâ€™une part. Et dâ€™autre part, la charge de travail est dÃ©placÃ©e vers une bonne conceptualisation du cas dâ€™Ã©tude. Les rÃ©sultats sont extrÃªmement dÃ©pendants de la formulation des patterns et des choix de verbalizers (i.e. choix du prompting). Ceux-ci impliquent une grande variabilitÃ© qui nâ€™est pas maÃ®trisÃ©e. De plus le PLM utilisÃ© - un modÃ¨le BERT dans le cas dâ€™Ekimetrics, cache des inconnues sur le corpus qui a servi Ã  son entraÃ®nement, son domaine dâ€™applicabilitÃ©, ses paramÃ¨tres. On touche lÃ  Ã  une limite dans laquelle lâ€™IA nâ€™est plus tout Ã  fait de lâ€™open science.</p><hr/><h1>Notes de Xavier que je n&#x27;ai pas mises</h1><h2>LIMITES et PISTES D&#x27;AMÃ‰LIORATIONS</h2><p>PLM ou Foundation modÃ¨le avec quelles donnÃ©es a-t-il Ã©tÃ© entraÃ®nÃ© ???</p><p>Que donnerait lâ€™utilisation de plusieurs PLM ?</p><p>une amÃ©lioration de ces approches est proposÃ© dans le papier <a href="https://arxiv.org/pdf/2103.11955.pdf">https://arxiv.org/pdf/2103.11955.pdf</a>.</p>]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[My first GitHub blog! (strongly inspired by Ekimetrics'...)]]></title>
            <link>https://drkapichu.github.io/blog/welcome</link>
            <guid>welcome</guid>
            <pubDate>Fri, 15 Oct 2021 00:00:00 GMT</pubDate>
            <description><![CDATA[Welcome to the first post! Short text, but sexy... People are eager to know more.]]></description>
            <content:encoded><![CDATA[<h1>And here is the content of my first blog...</h1><h2>Welcome to our technology website!</h2><p>We have been working in the Data Science industry for 15 years and are now the biggest pure player in Europe with 250+ data profiles. We have been benefiting from the open source community for a while, and we want to give back to the community by sharing insights on what we&#x27;ve learned over the years:</p><ul><li><a href="/blog">Blog</a> - read articles on various Data topics: from industrialization on cloud platforms to exotic Deep Learning algorithms</li><li><a href="/docs">Best practices &amp; convictions</a> - discover our programming best practices, our tech convictions and preferred technologies</li><li><a href="/opensource">Open source contributions</a> - browse our own open source contributions (Python libraries, code snippets)</li></ul><p>ğŸ’Œ After reading behind the scenes of the Data Science Company, feel free to <a href="mailto:inno@ekimetrics.com">send us a email</a> for any questions or feedbacks! </p><h2>About Ekimetrics</h2><p>Ekimetrics is the first pure player in Data Science in Europe. We operate from Paris, London, New York and Hong Kong with 250+ Data Scientists, Data Engineers, Full Stack Developers, strategy consultants and UX designers. </p><p>We help companies steer their data opportunity, build data capabilities, and deploy actionable solutions, to power up marketing and operational performance, as well as (re)energizing business models. Our primary focus is to deliver immediate business gains, while guaranteeing sustainable data capital for our clients.</p>]]></content:encoded>
        </item>
    </channel>
</rss>