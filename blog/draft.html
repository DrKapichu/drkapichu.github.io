<!doctype html>
<html lang="en" dir="ltr">
<head>
<meta charset="UTF-8">
<meta name="viewport" content="width=device-width,initial-scale=1">
<meta name="generator" content="Docusaurus v2.0.0-beta.14">
<link rel="alternate" type="application/rss+xml" href="/blog/rss.xml" title="datacraft blog RSS Feed">
<link rel="alternate" type="application/atom+xml" href="/blog/atom.xml" title="datacraft blog Atom Feed"><title data-react-helmet="true">Few Shot Learning - application de la méthode iPET | datacraft blog</title><meta data-react-helmet="true" property="og:title" content="Few Shot Learning - application de la méthode iPET | datacraft blog"><meta data-react-helmet="true" name="twitter:card" content="summary_large_image"><meta data-react-helmet="true" property="og:image" content="https://drkapichu.github.io//img/datacraft-team-3.JPG"><meta data-react-helmet="true" name="twitter:image" content="https://drkapichu.github.io//img/datacraft-team-3.JPG"><meta data-react-helmet="true" name="description" content="Draft of the first blog"><meta data-react-helmet="true" property="og:description" content="Draft of the first blog"><meta data-react-helmet="true" property="og:url" content="https://drkapichu.github.io//blog/draft"><meta data-react-helmet="true" name="docusaurus_locale" content="en"><meta data-react-helmet="true" name="docusaurus_tag" content="default"><meta data-react-helmet="true" name="keywords" content="datacraft,Deep Learning,Few Shot Learning,iPET"><link data-react-helmet="true" rel="icon" href="/img/datacraft_logo.png"><link data-react-helmet="true" rel="canonical" href="https://drkapichu.github.io//blog/draft"><link data-react-helmet="true" rel="alternate" href="https://drkapichu.github.io//blog/draft" hreflang="en"><link data-react-helmet="true" rel="alternate" href="https://drkapichu.github.io//blog/draft" hreflang="x-default"><link rel="stylesheet" href="/assets/css/styles.3166031a.css">
<link rel="preload" href="/assets/js/runtime~main.06b33ce7.js" as="script">
<link rel="preload" href="/assets/js/main.676c083f.js" as="script">
</head>
<body>
<script>!function(){function t(t){document.documentElement.setAttribute("data-theme",t)}var e=function(){var t=null;try{t=localStorage.getItem("theme")}catch(t){}return t}();t(null!==e?e:"dark")}()</script><div id="__docusaurus">
<div><a href="#" class="skipToContent_OuoZ">Skip to main content</a></div><nav class="navbar navbar--fixed-top"><div class="navbar__inner"><div class="navbar__items"><button aria-label="Navigation bar toggle" class="navbar__toggle clean-btn" type="button" tabindex="0"><svg width="30" height="30" viewBox="0 0 30 30" aria-hidden="true"><path stroke="currentColor" stroke-linecap="round" stroke-miterlimit="10" stroke-width="2" d="M4 7h22M4 15h22M4 23h22"></path></svg></button><a class="navbar__brand" href="/"><div class="navbar__logo"><img src="/img/datacraft_logo.png" alt=" " class="themedImage_TMUO themedImage--light_4Vu1"><img src="/img/datacraft_logo.png" alt=" " class="themedImage_TMUO themedImage--dark_uzRr"></div><b class="navbar__title">datacraft</b></a><a aria-current="page" class="navbar__item navbar__link navbar__link--active" href="/blog">Blog</a><a class="navbar__item navbar__link" href="/opensource">Open Source</a></div><div class="navbar__items navbar__items--right"><a href="https://datacraft.paris/" target="_blank" rel="noopener noreferrer" class="navbar__item navbar__link">datacraft website</a><a href="http://eepurl.com/hfkB9z" target="_blank" rel="noopener noreferrer" class="navbar__item navbar__link">Newsletter</a><a href="https://github.com/datacraft-paris" target="_blank" rel="noopener noreferrer" class="navbar__item navbar__link">Github</a></div></div><div role="presentation" class="navbar-sidebar__backdrop"></div></nav><div class="main-wrapper blog-wrapper"><div class="container container-wide margin-vert--lg"><div class="row"><div class="col col--2"></div><main class="col col--8"><article><header><h1 class="margin-bottom--sm blogPostTitle_RC3s">Few Shot Learning - application de la méthode iPET</h1><div class="margin-vert--md"><p>Draft of the first blog</p><time datetime="2022-02-04T00:00:00.000Z" class="blogPostDate_IAgm">February<!-- --> <!-- -->4<!-- -->, <!-- -->2022<!-- --> <!-- --> · <!-- -->9<!-- --> min read</time></div><div class="avatar margin-vert--md"><div class="avatar__intro"><h4 class="avatar__name">Written by <a href="mailto:julien.guyot@datacraft.paris" target="_blank" rel="noreferrer noopener">Kapichu</a></h4><small class="avatar__subtitle">astrophysicist</small></div></div><div class="margin-vert--md"><img class="img-blog-header" src="/img/blog/DataSparsity.jpg"></div></header><section class="markdown blog-article-custom"><p>(<a href="https://numenta.com/blog/2019/08/30/case-for-sparsity-in-neural-networks-part-1-pruning" target="_blank" rel="noopener noreferrer">source</a> de l&#x27;image de présentaion)</p><hr><h2 class="anchor anchorWithStickyNavbar_y2LR" id="quest-ce-que-le-few-shot-learning-fsl----titre-alternatif--sujet-du-jour--le-few-shot-learning-fsl">Qu’est ce que le Few Shot Learning (FSL) ? - titre alternatif : Sujet du jour : le Few Shot Learning (FSL)<a class="hash-link" href="#quest-ce-que-le-few-shot-learning-fsl----titre-alternatif--sujet-du-jour--le-few-shot-learning-fsl" title="Direct link to heading">​</a></h2><p>Il est bien connu que la puissance des méthodes de Machine Learning supervisées, et plus particulièrement de Deep Learning avec les réseaux de neurones, depuis le début des années 2000, a reposé sur la constitution de <strong>grands jeux de données labellisés</strong>. Deux éléments sont importants ici : ‘grands’ et ‘labellisés’.</p><p>Pour le premier point, ça représente par exemple des milliers, voire des millions d’images pour la Computer Vision et des millions d’ensembles de phrases pour le NLP. Concernant le second point, il signifie qu’au cours de son apprentissage, l’ordinateur compare son évaluation des données avec le label qu’un intervenant humain a associé à chaque donnée.</p><p>Dans le cas du <strong>Few Shot Learning (FSL)</strong>, les chercheurs veulent créer des méthodes capables d’apprendre avec peu de données, i.e. des dizaines ou des centaines, ce qui représente un gain de temps et d’énergie, tout en conservant des performances équivalentes aux modèles traditionnels bien sûr. C’est pourquoi en français on parle d’<strong>apprentissage frugal</strong>. Toutefois, en pratique les méthodes de FSL prennent un modèle traditionnel, pré-entraîné sur un grand nombre de données, et elles le spécialisent sur le cas d’usage via une courte phase d’apprentissage sur le petit jeu de données à disposition ; c’est du fine-tuning. Mais en plus, le Few Shot c’est une méthode qui va au-delà des méthodes traditionnelles, elle permet de faire du semi-supervisé, c’est ce qu’on va voir avec le cas d’usage.</p><h2 class="anchor anchorWithStickyNavbar_y2LR" id="le-cas-dusage---titre-alternatif--cest-quoi-le-problème-">Le cas d’usage - titre alternatif : C’est quoi le problème ?!<a class="hash-link" href="#le-cas-dusage---titre-alternatif--cest-quoi-le-problème-" title="Direct link to heading">​</a></h2><p>Ekimetrics s’est intéressé à l’apprentissage frugal pour exploiter les énormes jeux de données des petits commentaires quotidiens sur internet, avec une problématique de gain de temps… De la frugalité avec des énormes jeux de données ? On vous explique !</p><p>Mieux que le seul nombre d’étoiles d’un restaurant ou d’un hôtel, il s’agit de prendre en compte les avis dans les tweets, les posts, les brèves… qui sont par essence des données non labellisées et de les exploiter. L’annotation humaine de ces avis est inenvisageable. Ça coûterait trop cher, ça prendrait trop de temps, et il faudrait recommencer tous les jours pour suivre l’évolution du sentiment. En l&#x27;occurrence, pour la recherche d’Ekimetrics, le sujet d’étude porte sur des commentaires de restaurants.</p><p>Mais si la machine était capable d’évaluer les commentaires, à 2 Gigahertz, tout de suite le problème serait réglé. C’est là que le Few Shot, en utilisant la méthode PET, peut devenir utile.</p><p>Dans la suite, nous vous présentons la méthode PET, comment l’utiliser dans le cadre du FSL et enfin, comment Ekimetrics l’utilise sur les avis des consommateurs.</p><h2 class="anchor anchorWithStickyNavbar_y2LR" id="pet-quest-ce-que-cest-">PET qu’est ce que c’est ?<a class="hash-link" href="#pet-quest-ce-que-cest-" title="Direct link to heading">​</a></h2><p><strong>PET</strong> est l’acronyme de ‘<strong>Pattern Exploiting Training</strong>’. La méthode repose sur un ensemble fixe et prédéfini de <strong>patterns</strong> et de <strong>verbalizers</strong> et un <strong>Pre-trained Language Model</strong> a.k.a. <strong>PLM</strong>. Les patterns sont les phrases à trou (“It was…”, “Just…!”, “All in all, it was…”, “In summary, the restaurant is…”) et les verbalizers sont les mots qui peuvent compléter ces phrases et auxquels sont associées des notes chiffrées. On commence à retrouver les nombres que l’ordinateur aime tant !</p><p>Concrètement, reprenons notre exemple des évaluations des restaurants, la méthode consiste à :</p><ul><li>prendre un commentaire,</li><li>y associer aléatoirement un pattern,</li><li>soumettre le tout au PLM qui va le compléter en choisissant un verbalizer.</li></ul><p><img alt="image" src="/assets/images/PET-704c45e975116ca57616a2cd6fcc042e.png" title="Schema of a basic PET">{:.image-left}</p><p>Par exemple (voir Fig. 1), avec le commentaire “Best pizza ever!”, on construit la phrase à trou : “Best pizza ever! It was … .” que le PLM va compléter avec ‘great’ avec une confiance de 0.8, sachant que ce mot est noté +1.</p><h2 class="anchor anchorWithStickyNavbar_y2LR" id="fsl--pet--première-application-aux-avis-internet">FSL + PET : première application aux avis internet<a class="hash-link" href="#fsl--pet--première-application-aux-avis-internet" title="Direct link to heading">​</a></h2><p>Revenons à la masse brute des avis des consommateurs sur internet. <strong>PET est la méthode</strong> pour associer une note à un commentaire, le <strong>FSL est le moyen</strong> de traiter automatiquement tout le jeu de données, et le travail de l’algorithme se fait en deux étapes.</p><p>Dans un premier temps, on labellise un petit nombre de commentaires, une centaine par exemple, ce qui signifie qu’on associe une paire pattern plus verbalizer à ces commentaires, et on finetune le PLM avec cette centaine. Puis, une fois le PLM spécialisé, on le laisse labelliser tout le reste du jeu de données, automatiquement. Ça en fait une méthode semi-supervisée d’analyse de sentiment des commentaires.</p><p>Cependant, cette application basique présente des limites. D’une part, le verbalizer donné par le PLM peut ne pas être le plus adapté au commentaire et, d’autre part, c’est très ambitieux de spécialiser le PLM une fois sur une centaine d’exemples pour ensuite en traiter des dizaines de milliers ou plus. C’est pourquoi les chercheurs ont développé une méthode de distillation qui augmente la robustesse de PET, c’est la méthode <strong>iPET : iterative PET</strong>.</p><h2 class="anchor anchorWithStickyNavbar_y2LR" id="iterativepet--une-méthode-de-distillation-astucieuse">i(terative)PET : une méthode de distillation astucieuse<a class="hash-link" href="#iterativepet--une-méthode-de-distillation-astucieuse" title="Direct link to heading">​</a></h2><p>Une image peut valoir mille mots…</p><p><img src="/assets/images/iPET-951a114446fe9163038dfa96702f07a9.png"></p><p>… Mais quelques mots seront quand même nécessaires pour expliquer cette image !</p><p>Tout d’abord, le schéma de gauche sur la figure présente l’adaptation de PET qui permet d’obtenir le label le plus adapté au commentaire… en moyenne. En effet, il s’agit ‘simplement’ de <strong>faire travailler des méthodes PET indépendantes en parallèle</strong> (trois sur le schéma). Les trois cellules ont le même PLM au départ, et elles travaillent sur les mêmes commentaires, mais avec des patterns différents. Dans la phase d’entraînement sur les données labellisées, les PLMs se spécialisent différemment. Puis, durant la phase de travail, pour un même commentaire ils produisent des <strong>paires pattern-verbalizers</strong> (appelées <strong>PVPs</strong> sur le schéma) indépendamment les uns des autres ; possiblement les mêmes, mais pas avec les mêmes probas. Enfin, <strong>en sortie</strong> ces (trois) labels sont utilisés pour calculer <strong>un soft-label</strong>, i.e. un <strong>label moyen</strong>.</p><p>Ensuite, sur la droite est présenté le caractère itératif de la méthode iPET. Elle consiste à diviser le jeu labellisés sur plusieurs itérations (indiquées par les exposants allant de 0 à k) et à diviser encore à chaque itération entre plusieurs méthodes parallèles (indiquées par les indices allant de 0 à 4). Mais attention, chacun des quatre modèles ici fait du soft-labelling comme présenté à gauche de la figure, c’est-à-dire qu’ils contiennent plusieurs méthodes en parallèle.</p><p>Donc, si l’on suppose que l’on part pour trois itérations, l’information labellisée est distillée de la manière suivante. À l’itération 0 sur le schéma, on prend un tiers des données labellisées, et on fournit un quart de ces données à chaque modèle pour le finetuner, avant de prendre un tiers des données à labelliser et d’en fournir un quart à chaque modèle pour soft-labellisation. Ce qui constitue la fin de la première itération.</p><p>À la deuxième itération - itération 1 sur le schéma, on commence à nouveau par un phase de fine-tuning, mais avec un jeu de données labellisées constitué pour partie des données annotées par un être humain (le deuxième tiers), et pour partie de données soft-labellisées. Toutefois, on fait attention à ce qu’un modèle ne s’entraîne pas avec des données qu’il a lui-même soft-labellisé, pour éviter qu’il renforce ses biais… on distille ! Par exemple sur le schéma, à l’itération 1, le jeu d’entraînement T fourni au modèle 4, i.e. T14, est constitué de données soft-labellisées par les modèles 1 et 2, en plus des données annotées par l’humain. Puis on prend le deuxième tiers de données à annoter, on en fournit un quart à chaque modèle pour soft-labellisation et on finit la deuxième itération.</p><p>Pour la troisième itération, vous avez compris le principe je pense…   </p><p>À la fin, les millions de commentaires sont plutôt bien soft-labellisés, à la vitesse de la machine et au coût de l’électricité, tout est prêt pour un classifieur sur le schéma d’Ekimetrics et je vous ai expliqué tous les termes entourés sur la figure et présenté toutes les étapes. </p><h2 class="anchor anchorWithStickyNavbar_y2LR" id="avantages-inconvénients-limites-et-améliorations">Avantages, inconvénients, limites et améliorations.<a class="hash-link" href="#avantages-inconvénients-limites-et-améliorations" title="Direct link to heading">​</a></h2><p>Nous avons déjà vu certains des avantages. Internet est une place sur laquelle il y a pléthore d’avis en tout genre : films, restaurants, hôtels, produits de grande consommation, lieux divers… Annoter ces données serait un travail coûteux et sans fin, nous l’avons dit. L’approche iPET permet d’automatiser cette étape, à la vitesse de l’ordinateur et quel que soit le cas d’étude.</p><p>Du point de vue des performances, Ekimetrics a indiqué avoir une précision de 88% avec seulement 50 données labellisées au départ, et même 84% avec 10 données labellisées !! En comparaison, les modèles supervisés peuvent atteindre des précisions de 99%, mais au prix d’un énorme travail de pré-traitement. C’est donc un pas conceptuel de plus dans la réduction de la supervision.</p><p>Toutefois, le domaine d’application se restreint à des données textuelles assez courtes d’une part. Et d’autre part, la charge de travail est déplacée vers une bonne conceptualisation du cas d’étude. Les résultats sont extrêmement dépendants de la formulation des patterns et des choix de verbalizers (i.e. choix du prompting). Ceux-ci impliquent une grande variabilité qui n’est pas maîtrisée. De plus le PLM utilisé - un modèle BERT dans le cas d’Ekimetrics, cache des inconnues sur le corpus qui a servi à son entraînement, son domaine d’applicabilité, ses paramètres. On touche là à une limite dans laquelle l’IA n’est plus tout à fait de l’open science.</p><hr><header><h1>Notes de Xavier que je n&#x27;ai pas mises</h1></header><h2 class="anchor anchorWithStickyNavbar_y2LR" id="limites-et-pistes-daméliorations">LIMITES et PISTES D&#x27;AMÉLIORATIONS<a class="hash-link" href="#limites-et-pistes-daméliorations" title="Direct link to heading">​</a></h2><p>PLM ou Foundation modèle avec quelles données a-t-il été entraîné ???</p><p>Que donnerait l’utilisation de plusieurs PLM ?</p><p>une amélioration de ces approches est proposé dans le papier <a href="https://arxiv.org/pdf/2103.11955.pdf" target="_blank" rel="noopener noreferrer">https://arxiv.org/pdf/2103.11955.pdf</a>.</p></section><footer class="row margin-vert--lg"><div class="col"><strong>Tags:</strong><a class="margin-horiz--sm" href="/blog/tags/few-shot-learning">Few Shot Learning</a><a class="margin-horiz--sm" href="/blog/tags/pet">PET</a><a class="margin-horiz--sm" href="/blog/tags/i-pet">iPET</a><a class="margin-horiz--sm" href="/blog/tags/semi-supervised">semi-supervised</a></div></footer></article><div class="margin-vert--xl"><nav class="pagination-nav docusaurus-mt-lg" aria-label="Blog post page navigation"><div class="pagination-nav__item"><a class="pagination-nav__link" href="/blog/testou"><div class="pagination-nav__sublabel">Newer Post</div><div class="pagination-nav__label">« <!-- -->This is a test for the actions</div></a></div><div class="pagination-nav__item pagination-nav__item--next"><a class="pagination-nav__link" href="/blog/welcome"><div class="pagination-nav__sublabel">Older Post</div><div class="pagination-nav__label">My first GitHub blog! (strongly inspired by Ekimetrics&#x27;...)<!-- --> »</div></a></div></nav></div></main><div class="col col--2"><div class="tableOfContents_vrFS thin-scrollbar"><ul class="table-of-contents table-of-contents__left-border"><li><a href="#quest-ce-que-le-few-shot-learning-fsl----titre-alternatif--sujet-du-jour--le-few-shot-learning-fsl" class="table-of-contents__link toc-highlight">Qu’est ce que le Few Shot Learning (FSL) ? - titre alternatif : Sujet du jour : le Few Shot Learning (FSL)</a></li><li><a href="#le-cas-dusage---titre-alternatif--cest-quoi-le-problème-" class="table-of-contents__link toc-highlight">Le cas d’usage - titre alternatif : C’est quoi le problème ?!</a></li><li><a href="#pet-quest-ce-que-cest-" class="table-of-contents__link toc-highlight">PET qu’est ce que c’est ?</a></li><li><a href="#fsl--pet--première-application-aux-avis-internet" class="table-of-contents__link toc-highlight">FSL + PET : première application aux avis internet</a></li><li><a href="#iterativepet--une-méthode-de-distillation-astucieuse" class="table-of-contents__link toc-highlight">i(terative)PET : une méthode de distillation astucieuse</a></li><li><a href="#avantages-inconvénients-limites-et-améliorations" class="table-of-contents__link toc-highlight">Avantages, inconvénients, limites et améliorations.</a></li><li><a href="#limites-et-pistes-daméliorations" class="table-of-contents__link toc-highlight">LIMITES et PISTES D&#39;AMÉLIORATIONS</a></li></ul></div></div></div></div></div><footer class="footer"><div class="container container-fluid"><div class="row footer__links"><div class="col footer__col"><div class="footer__title">About us</div><ul class="footer__items"><li class="footer__item"><a href="https://datacraft.paris/about-us/" target="_blank" rel="noopener noreferrer" class="footer__link-item">Who we are ?</a></li><li class="footer__item"><a href="http://eepurl.com/hfkB9z" target="_blank" rel="noopener noreferrer" class="footer__link-item">Subscribe to our newsletter</a></li></ul></div></div><div class="footer__bottom text--center"></div></div></footer></div>
<script src="/assets/js/runtime~main.06b33ce7.js"></script>
<script src="/assets/js/main.676c083f.js"></script>
</body>
</html>